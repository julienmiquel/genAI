{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579aaa05-bef2-414a-8da0-b4824dbcb552",
   "metadata": {},
   "source": [
    "\n",
    "# **Gen** ret<strong><font color=\"red\">AI</font></strong>l\n",
    "\n",
    "Customer search:\n",
    "* I search flower for **weading.**\n",
    "* I search flower for **mother day.**\n",
    "* I search flower for **valentine day.**\n",
    "\n",
    "Company provide:\n",
    "* I found the same product <strong><font color=\"red\">contextualized</font></strong> to my search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301178ef-fc45-4f3e-8142-f956c84efb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZERO_SHOT_PROMPT = '''Product description **PRODUCT** according the **THEMA**\n",
    "'''\n",
    "\n",
    "ZERO_SHOT_PROMPT = '''Why this **PRODUCT** is perfect for the special event: **THEMA**\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f0a08",
   "metadata": {},
   "source": [
    "# Init project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28756a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the google cloud project id\n",
    "\n",
    "def init_gcloud_(project_id = \"ucs-fishfood-8\"):\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    # [START gae_python37_app_init_gcloud]\n",
    "    !gcloud config set project $project_id\n",
    "\n",
    "def init_project_genappbuilder():\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    init_gcloud_(project_id = \"ucs-fishfood-8\")\n",
    "\n",
    "\n",
    "def init_project_images():\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    init_gcloud_(project_id = \"cloud-llm-preview4\")\n",
    "\n",
    "\n",
    "def init_project_workstations():\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    init_gcloud_(project_id = \"cloud-workstations-demo-2\")\n",
    "\n",
    "def init_project_ml_api():\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    init_gcloud_(project_id = \"google.com:ml-baguette-demos\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9055a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b521a34b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569f6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8665d051",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6dd21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369790e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f7983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e9fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73e012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d7f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4837996c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Image Gen (not used in the demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"google.com:ml-baguette-demos\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "MODEL_NAME = \"text-bison@001\" # @param {type:\"string\"}\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer $(gcloud auth application-default print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "https://us-central1-aiplatform.googleapis.com/ui/projects/google.com:ml-baguette-demos/locations/us-central1/models:upload \\\n",
    "-d '{\"model\": {\"display_name\": \"vision-generative-model\",\"large_model_reference\": {\"name\": \"imagegeneration-001\"}}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "gcloud_token = !gcloud auth print-access-token\n",
    "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "\n",
    "ACCESS_TOKEN = gcloud_token[0]\n",
    "\n",
    "# This endpoint is what was available from the Private API Documentation\n",
    "# https://cloud.devsite.corp.google.com/vision-ai/docs/priv/generate-images-api\n",
    "ENDPOINT_URL = 'projects/66194518407/locations/us-central1/endpoints/4549422873969688576'\n",
    "\n",
    "# This endpoint below is from the Internal Fishfooding Guide: go/IG-fishfooding\n",
    "FF_ENDPOINT_URL = 'projects/cloud-lvm-fishfooding/locations/us-central1/endpoints/6988653136307027968'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def image_gen_model(prompt, sampleImageSize, sampleCount, endpointType='Prod', seed=None):\n",
    "  headers = {\n",
    "      'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "      'Content-Type': 'application/json; charset=UTF-8'\n",
    "  }\n",
    "  # Advanced option, try different the seed numbers\n",
    "  # any random integer number range: (0, 2147483647)\n",
    "  if seed==None:\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount}}\n",
    "  else:\n",
    "    # Use & provide a seed, if possible, so that we can reproduce the results when needed.\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount, \"seed\": seed}}\n",
    "\n",
    "  print(data)\n",
    "  if endpointType=='Prod':\n",
    "    # Prod usage\n",
    "    response = requests.post(f'https://us-central1-aiplatform.googleapis.com/v1/{ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "  else:\n",
    "    # Autopush usage\n",
    "    response = requests.post(f'https://us-central1-autopush-aiplatform.sandbox.googleapis.com/v1/{FF_ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa54adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click `Show code` in the code cell (Don't forget to run this cell). { display-mode: \"form\" }\n",
    "\n",
    "sampleImageSize = '1024' #@param {type:\"string\"}\n",
    "sampleCount = 6 #@param {type:\"integer\"}\n",
    "prompt = 'audacious and whimsical fantasy house shaped like pasion fruit with windows and door, in the desert' #@param {type:\"string\"}\n",
    "endpointType = \"Fishfood\" #@param [\"Prod\", \"Fishfood\"]\n",
    "\n",
    "# Advanced option, try different the seed numbers\n",
    "# any random integer number range: (0, 2147483647)\n",
    "seed = None #@param {type:\"raw\"}\n",
    "\n",
    "print('sampleImageSize:', sampleImageSize)\n",
    "print('sampleCount:', sampleCount)\n",
    "print('prompt', prompt)\n",
    "print('endpointType', endpointType)\n",
    "print('seed', seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e040de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use & provide a seed, if possible, so that we can reproduce the results when needed.\n",
    "response = image_gen_model(prompt, sampleImageSize, sampleCount, endpointType, seed)\n",
    "json_response = json.loads(response.text)\n",
    "\n",
    "try:\n",
    "  predictions = json_response['predictions']\n",
    "except:\n",
    "  print(\"An error occured calling the API.\")\n",
    "  print(\"1. Check if response was not blocked based on policy violation, check if the UI behaves the same way...\")\n",
    "  print(\"2. Try a different prompt to see if that was the problem.\\n\")\n",
    "  print(response.text)\n",
    "  # print(dir(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08dee8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c119f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def image_gen_model(prompt, sampleImageSize, sampleCount, endpointType='Prod', seed=None):\n",
    "  init_project_images()\n",
    "  gcloud_token = !gcloud auth print-access-token\n",
    "  gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "  ACCESS_TOKEN = gcloud_token[0]\n",
    "\n",
    "  # This endpoint is what was available from the Private API Documentation\n",
    "  # https://cloud.devsite.corp.google.com/vision-ai/docs/priv/generate-images-api\n",
    "  ENDPOINT_URL = 'projects/66194518407/locations/us-central1/endpoints/4549422873969688576'\n",
    "\n",
    "  # This endpoint below is from the Internal Fishfooding Guide: go/IG-fishfooding\n",
    "  #FF_ENDPOINT_URL = 'projects/cloud-lvm-fishfooding/locations/us-central1/endpoints/6988653136307027968'\n",
    "\n",
    "  headers = {\n",
    "      'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "      'Content-Type': 'application/json; charset=UTF-8'\n",
    "  }\n",
    "  # Advanced option, try different the seed numbers\n",
    "  # any random integer number range: (0, 2147483647)\n",
    "  if seed==None:\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount}}\n",
    "  else:\n",
    "    # Use & provide a seed, if possible, so that we can reproduce the results when needed.\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount, \"seed\": seed}}\n",
    "\n",
    "  print(data)\n",
    "  #if endpointType=='Prod':\n",
    "    # Prod usage\n",
    "  response = requests.post(f'https://us-central1-aiplatform.googleapis.com/v1/{ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "  #else:\n",
    "    # Autopush usage\n",
    "  #  response = requests.post(f'https://us-central1-autopush-aiplatform.sandbox.googleapis.com/v1/{FF_ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def70516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click `Show code` in the code cell (Don't forget to run this cell). { display-mode: \"form\" }\n",
    "\n",
    "sampleImageSize = '1024' #@param {type:\"string\"}\n",
    "sampleCount = 6 #@param {type:\"integer\"}\n",
    "prompt = 'audacious and whimsical fantasy house shaped like pasion fruit with windows and door, in the desert' #@param {type:\"string\"}\n",
    "endpointType = \"Prod\" #@param [\"Prod\", \"Fishfood\"]\n",
    "\n",
    "# Advanced option, try different the seed numbers\n",
    "# any random integer number range: (0, 2147483647)\n",
    "seed = None #@param {type:\"raw\"}\n",
    "\n",
    "print('sampleImageSize:', sampleImageSize)\n",
    "print('sampleCount:', sampleCount)\n",
    "print('prompt', prompt)\n",
    "print('endpointType', endpointType)\n",
    "print('seed', seed)\n",
    "\n",
    "# Use & provide a seed, if possible, so that we can reproduce the results when needed.\n",
    "response = image_gen_model(prompt, sampleImageSize, sampleCount, endpointType, seed)\n",
    "json_response = json.loads(response.text)\n",
    "\n",
    "try:\n",
    "  predictions = json_response['predictions']\n",
    "except:\n",
    "  print(\"An error occured calling the API.\")\n",
    "  print(\"1. Check if response was not blocked based on policy violation, check if the UI behaves the same way...\")\n",
    "  print(\"2. Try a different prompt to see if that was the problem.\\n\")\n",
    "  print(response.text)\n",
    "  # print(dir(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da2447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e70b118",
   "metadata": {},
   "source": [
    "# Palm LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d718b7-5c0a-47a2-825f-ed6e4b49255e",
   "metadata": {},
   "source": [
    "#### The `top_k` parameter (range: 0.0 - 40, default 40)\n",
    "\n",
    "##### What is _top_k_?\n",
    "`top_k` changes how the model selects tokens for output. A `top_k` of 1 means the selected token is the most probable among all tokens in the model's vocabulary (also called greedy decoding). In contrast, a `top_k` of 3 means that the next token is selected from the top 3 most probable tokens (using temperature). For each token selection step, the `top_k` tokens with the highest probabilities are sampled. Then tokens are further filtered based on `top_p` with the final token selected using temperature sampling.\n",
    "\n",
    "##### How does _top_k_ affect the response?\n",
    "\n",
    "Specify a lower value for less random responses and a higher value for more random responses.\n",
    "\n",
    "For more information on the `top_k` parameter for text models, please refer to the [documentation on model parameters](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models#text_model_parameters).\n",
    "                                                                                                                       \n",
    "#### The `top_p` parameter (range: 0.0 - 1.0, default 0.95)\n",
    "                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74be919-0249-48f6-8e18-fac317201e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel,\\\n",
    "                                            ChatModel,\\\n",
    "                                            InputOutputTextPair,\\\n",
    "                                            TextEmbeddingModel\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "\n",
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "\n",
    "\n",
    "def generative_example(text_input, temperature=0.6, top_k=40, top_p=0.9, max_output_tokens=512):\n",
    "    \"\"\"Text Generation with a Large Language Model.\"\"\"\n",
    "    response = generation_model.predict(\n",
    "        text_input,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k, # default top_k=1\n",
    "        top_p=top_p, # default top_p=0\n",
    "        max_output_tokens=max_output_tokens, # default 32\n",
    "    )\n",
    "    #print(response.text)\n",
    "    \n",
    "    return response\n",
    "\n",
    "generative_example(ZERO_SHOT_PROMPT.replace('**PRODUCT**',\"flower\").replace('**THEMA**',\"weading\") )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d2f21f",
   "metadata": {},
   "source": [
    "# Cloud vision to enrich text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c60af-d22e-4944-b42b-30f7fe65588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from google.cloud import vision\n",
    "\n",
    "\n",
    "def analyze_image_from_uri(\n",
    "    image_uri: str,\n",
    "    feature_types: Sequence,\n",
    ") -> vision.AnnotateImageResponse:\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = image_uri\n",
    "    features = [vision.Feature(type_=feature_type) for feature_type in feature_types]\n",
    "    request = vision.AnnotateImageRequest(image=image, features=features)\n",
    "\n",
    "    response = client.annotate_image(request=request)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def print_labels(response: vision.AnnotateImageResponse):\n",
    "    print(\"LABELS \" +\"==\" * 80)\n",
    "    for label in response.label_annotations:\n",
    "        print(\n",
    "            f\"{label.score:4.0%}\",\n",
    "            f\"{label.description:5}\",\n",
    "            sep=\" | \",\n",
    "        )\n",
    "    return response.label_annotations\n",
    "\n",
    "def print_text(response: vision.AnnotateImageResponse):\n",
    "    print(\"TEXT \"+\"==\" * 80)\n",
    "    for annotation in response.text_annotations:\n",
    "        vertices = [f\"({v.x},{v.y})\" for v in annotation.bounding_poly.vertices]\n",
    "        print(\n",
    "            f\"{repr(annotation.description):42}\",\n",
    "            \",\".join(vertices),\n",
    "            sep=\" | \",\n",
    "        )\n",
    "        \n",
    "def print_landmarks(response: vision.AnnotateImageResponse, min_score: float = 0.5):\n",
    "    print(\"LANDMARKS \" +\"==\" * 80)\n",
    "    for landmark in response.landmark_annotations:\n",
    "        if landmark.score < min_score:\n",
    "            continue\n",
    "        vertices = [f\"({v.x},{v.y})\" for v in landmark.bounding_poly.vertices]\n",
    "        lat_lng = landmark.locations[0].lat_lng\n",
    "        print(\n",
    "            f\"{landmark.description:18}\",\n",
    "            \",\".join(vertices),\n",
    "            f\"{lat_lng.latitude:.5f}\",\n",
    "            f\"{lat_lng.longitude:.5f}\",\n",
    "            sep=\" | \",\n",
    "        )       \n",
    "\n",
    "def print_objects(response: vision.AnnotateImageResponse):\n",
    "    print(\"OBJECTS \" +\"==\" * 80)\n",
    "    for obj in response.localized_object_annotations:\n",
    "        nvertices = obj.bounding_poly.normalized_vertices\n",
    "        print(\n",
    "            f\"{obj.score:4.0%}\",\n",
    "            f\"{obj.name:15}\",\n",
    "            f\"{obj.mid:10}\",\n",
    "            \",\".join(f\"({v.x:.1f},{v.y:.1f})\" for v in nvertices),\n",
    "            sep=\" | \",\n",
    "        )   \n",
    "\n",
    "def print_logos(response: vision.AnnotateImageResponse, min_score: float = 0.5):\n",
    "    print(\"LOGO \"+\"==\" * 80)\n",
    "\n",
    "    for logo in response.logo_annotations:\n",
    "        if logo.score < min_score:\n",
    "            continue\n",
    "        \n",
    "        print('Logos:')\n",
    "        print(logo.description)\n",
    "    \n",
    "def print_safe(response: vision.AnnotateImageResponse):\n",
    "    print(\"SAFE \"+\"==\" * 80)\n",
    "\n",
    "    safe = response.safe_search_annotation\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    print('Safe search:')\n",
    "\n",
    "    print(f'adult: {likelihood_name[safe.adult]}')\n",
    "    print(f'medical: {likelihood_name[safe.medical]}')\n",
    "    print(f'spoofed: {likelihood_name[safe.spoof]}')\n",
    "    print(f'violence: {likelihood_name[safe.violence]}')\n",
    "    print(f'racy: {likelihood_name[safe.racy]}')\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))    \n",
    "    \n",
    "\n",
    "def print_web(response: vision.AnnotateImageResponse):\n",
    "    print(\"WEB \"+\"==\" * 80)\n",
    "\n",
    "    annotations = response.web_detection\n",
    "\n",
    "    if annotations.best_guess_labels:\n",
    "        for label in annotations.best_guess_labels:\n",
    "            print(f'\\nBest guess label: {label.label}')\n",
    "\n",
    "    if annotations.pages_with_matching_images:\n",
    "        print('\\n{} Pages with matching images found:'.format(\n",
    "            len(annotations.pages_with_matching_images)))\n",
    "\n",
    "        for page in annotations.pages_with_matching_images:\n",
    "            print(f'\\n\\tPage url   : {page.url}')\n",
    "\n",
    "            if page.full_matching_images:\n",
    "                print('\\t{} Full Matches found: '.format(\n",
    "                       len(page.full_matching_images)))\n",
    "\n",
    "                for image in page.full_matching_images:\n",
    "                    print(f'\\t\\tImage url  : {image.url}')\n",
    "\n",
    "            if page.partial_matching_images:\n",
    "                print('\\t{} Partial Matches found: '.format(\n",
    "                       len(page.partial_matching_images)))\n",
    "\n",
    "                for image in page.partial_matching_images:\n",
    "                    print(f'\\t\\tImage url  : {image.url}')\n",
    "\n",
    "    if annotations.web_entities:\n",
    "        print('\\n{} Web entities found: '.format(\n",
    "            len(annotations.web_entities)))\n",
    "\n",
    "        for entity in annotations.web_entities:\n",
    "            print(f'\\n\\tScore      : {entity.score}')\n",
    "            print(f'\\tDescription: {entity.description}')\n",
    "\n",
    "    if annotations.visually_similar_images:\n",
    "        print('\\n{} visually similar images found:\\n'.format(\n",
    "            len(annotations.visually_similar_images)))\n",
    "\n",
    "        for image in annotations.visually_similar_images:\n",
    "            print(f'\\tImage url    : {image.url}')\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41abb4-88b7-4994-838b-612b8bccb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_labels (\n",
    "image_uri = \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"\n",
    "):\n",
    "    features = [vision.Feature.Type.LABEL_DETECTION, \n",
    "                vision.Feature.Type.LANDMARK_DETECTION, \n",
    "                vision.Feature.Type.LOGO_DETECTION,\n",
    "    #            vision.Feature.Type.SAFE_SEARCH_DETECTION,\n",
    "                vision.Feature.Type.WEB_DETECTION,\n",
    "                vision.Feature.Type.TEXT_DETECTION,\n",
    "                vision.Feature.Type.OBJECT_LOCALIZATION]\n",
    "\n",
    "    features = [vision.Feature.Type.LABEL_DETECTION] \n",
    "\n",
    "    response = analyze_image_from_uri(image_uri, features)\n",
    "    labels = print_labels(response)\n",
    "    list_labels = [x.description for x in list(filter(lambda x: (x.score > 0.80 ), labels)) ]\n",
    "\n",
    "    return list_labels\n",
    "\n",
    "image_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d12c8-c9cd-495e-983d-4213c8b3697a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f6b0fe2",
   "metadata": {},
   "source": [
    "# Translate API to support multiple input/output languages (only english is supported by Palm actually)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-translate==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91146c7-110c-42c5-9f5c-3da2d2bae1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(target, text):\n",
    "\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "\n",
    "    print(\"Text: {}\".format(result[\"input\"]))\n",
    "    print(\"Translation: {}\".format(result[\"translatedText\"]))\n",
    "    print(\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
    "    \n",
    "    if isinstance(result[\"translatedText\"], bytes):\n",
    "        print(\"bytes\")\n",
    "        text = result[\"translatedText\"].decode(\"utf-8\")\n",
    "        return text\n",
    "        \n",
    "    unicode_string = result[\"translatedText\"]\n",
    "    \n",
    "    return clean_text(unicode_string)\n",
    "    \n",
    "# TODO: Clean me ugly code\n",
    "def clean_text(s : str):    \n",
    "    return s.replace(\"&#39;\", \"'\")\n",
    "\n",
    "init_project_ml_api()\n",
    "translate_text( \"FR\", \"The tree is perfect for the special event: wedding because it is covered in beautiful pink flowers. The flowers are a symbol of love and romance, and they make the tree look very elegant and festive. The tree would be a beautiful addition to any wedding ceremony or reception, and it would make a lasting impression on guests.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643409f7-d88a-402d-a036-39102027137a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6818c-ea68-4ddd-abed-697cd7617318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94d23387",
   "metadata": {},
   "source": [
    "# gradio interface used by the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d0dec-7a5c-411b-8b60-4d09431831a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "362b1d78-4e61-4f6a-bf48-cbda6a61bf40",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <h1>My First JavaScript</h1>\n",
    "    <button type=\"testButton\" onclick=\"testFn()\"> Start </button>\n",
    "    \n",
    "    <p id=\"demo\"></p>\n",
    "    \n",
    "    <!-- Element that opens the widget on click. It does not have to be an input -->\n",
    "    <input placeholder=\"Search here\" id=\"searchWidgetTrigger\" />\n",
    "\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "scripts = \"\"\"\n",
    "async () => {\n",
    "   // set testFn() function on globalThis, so you html onlclick can access it\n",
    "    globalThis.testFn = () => {\n",
    "      document.getElementById('demo').innerHTML = \"Hello\"\n",
    "    }\n",
    "\n",
    "\n",
    "<!-- Gen App Builder widget bundle -->\n",
    "<script src=\"https://gen-ai-app-builder.appspot.com/preview/client\"></script>\n",
    "\n",
    "<!-- Search widget element is not visible by default -->\n",
    "<gen-search-widget\n",
    "  widgetConfigName=\"projects/210552312048/locations/global/collections/default_collection/dataStores/interflora_website/widgetConfigs/default_search_widget_config\"\n",
    "  apiKey=\"AIzaSyALVFMY1VdfXHWrtx-o1uiAcHyeKq_8N5U\"\n",
    "  triggerId=\"searchWidgetTrigger\">\n",
    "</gen-search-widget>\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks() as demo1:   \n",
    "    input_mic = gr.HTML(html)\n",
    "    out_text  = gr.Textbox()\n",
    "    # run script function on load,\n",
    "    demo1.load(None,None,None,_js=scripts)\n",
    "\n",
    "   \n",
    "demo1.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4d77c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48777403-3039-4054-8644-bf1e0e023325",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gradio==3.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624814c-2e7d-4ec0-8c8d-2c365a95cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --user --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6774f-09c8-4d62-9c85-6d5dcabb6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "genappbuilder_demo_url = \"https://c5c9fecc7e8a479b1e.gradio.live\"\n",
    "client_genappbuilder = Client(genappbuilder_demo_url)\n",
    "\n",
    "client_genappbuilder.view_api()\n",
    "\n",
    "client_genappbuilder.predict(\"fleur\",  fn_index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4aee9-f0b2-4775-81b1-fda66e7e4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<div class=\"PushMomentsFirst-picture\"><picture class=\"BlockPicture BlockResizePicture\"><source srcset=\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/Bandeau-principal-MothersDay2023-Octopus-02.jpg?frz-width=640&amp;frz-height=450&amp;frz-gravity=center&amp;frz-enlarge=true&amp;context=bWFzdGVyfHJvb3R8MjIwMjIwfGltYWdlL2pwZWd8aGIwL2gzZC85NTc5NzE5OTgzMTM0LmpwZ3wxMDg1YjM1Y2E0NDkzMDk1NWRhMTg0ODViNWU5YzBlYTk2OTk2ZDI3OTE5ODc2MjNiY2M3NDMyYmZjNTdjMGJl 1x\" media=\"(max-width: 639px)\"><source srcset=\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/Bandeau-principal-MothersDay2023-Octopus-02.jpg?frz-width=959&amp;frz-height=450&amp;frz-gravity=center&amp;frz-enlarge=true&amp;context=bWFzdGVyfHJvb3R8MjIwMjIwfGltYWdlL2pwZWd8aGIwL2gzZC85NTc5NzE5OTgzMTM0LmpwZ3wxMDg1YjM1Y2E0NDkzMDk1NWRhMTg0ODViNWU5YzBlYTk2OTk2ZDI3OTE5ODc2MjNiY2M3NDMyYmZjNTdjMGJl 1x\" media=\"(max-width: 959px)\"><source srcset=\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/Bandeau-principal-MothersDay2023-Octopus-02.jpg?frz-width=1600&amp;frz-height=450&amp;frz-gravity=center&amp;frz-enlarge=true&amp;context=bWFzdGVyfHJvb3R8MjIwMjIwfGltYWdlL2pwZWd8aGIwL2gzZC85NTc5NzE5OTgzMTM0LmpwZ3wxMDg1YjM1Y2E0NDkzMDk1NWRhMTg0ODViNWU5YzBlYTk2OTk2ZDI3OTE5ODc2MjNiY2M3NDMyYmZjNTdjMGJl 1x\" media=\"(min-width: 960px)\"> <img src=\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/Bandeau-principal-MothersDay2023-Octopus-02.jpg?context=bWFzdGVyfHJvb3R8MjIwMjIwfGltYWdlL2pwZWd8aGIwL2gzZC85NTc5NzE5OTgzMTM0LmpwZ3wxMDg1YjM1Y2E0NDkzMDk1NWRhMTg0ODViNWU5YzBlYTk2OTk2ZDI3OTE5ODc2MjNiY2M3NDMyYmZjNTdjMGJl\" alt=\"Fête des Mères Dimanche 4 juin\" width=\"480\" height=\"480\" fetchpriority=\"high\"></picture></div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda468a-356f-47a0-8835-670aa76e012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import base64\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "\n",
    "gcloud_token = !gcloud auth print-access-token\n",
    "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "\n",
    "ACCESS_TOKEN = gcloud_token[0]\n",
    "\n",
    "endpointType = \"Prod\" #@param [\"Prod\", \"Fishfood\"]\n",
    "seed=0\n",
    "\n",
    "def update(search,\n",
    "           theme,\n",
    "           language,\n",
    "           temperature,\n",
    "           top_k,\n",
    "           top_p,\n",
    "           max_output_tokens,\n",
    "           endpointType='Prod' #,           seed=None\n",
    "          ):\n",
    "    \n",
    "    title, link, snippet, description, image = client_genappbuilder.predict(search,  fn_index=0)\n",
    "    print(\"Title: \", title)\n",
    "    print(\"Link: \", link)\n",
    "    print(\"Description: \", description)\n",
    "    print(\"Snippet: \", snippet)\n",
    "    print(\"Image: \", image)\n",
    "    \n",
    "    images = []\n",
    "  \n",
    "    images.append(Image.open(requests.get(image , stream=True).raw))\n",
    "\n",
    "    #image_uri = \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"\n",
    "\n",
    "    list_labels = image_labels(image)\n",
    "    prompt = (ZERO_SHOT_PROMPT.replace('**PRODUCT**',search).replace('**THEMA**',theme) + \" with the labels: \"+ \", \".join(list_labels))\n",
    "    \n",
    "    \n",
    "    print(prompt)\n",
    "    print(temperature)\n",
    "    print(float(temperature))\n",
    "    response = generative_example(prompt, temperature=float(temperature), top_k=top_k, top_p=top_p, max_output_tokens=max_output_tokens)\n",
    "\n",
    "    print(response.text)\n",
    "    \n",
    "    if response._prediction_response[0][0]['safetyAttributes']['blocked'] == True:\n",
    "        print(\"Function not available\")\n",
    "    else:\n",
    "        print(\"LLM answer: \\n\",response.text)    \n",
    "\n",
    "    import pandas as pd\n",
    "    safety_categories = response._prediction_response[0][0]['safetyAttributes']['categories']\n",
    "    safety_scores = response._prediction_response[0][0]['safetyAttributes']['scores']\n",
    "    safety_blocked = response._prediction_response[0][0]['safetyAttributes']['blocked']\n",
    "\n",
    "    safety_attributes_df = pd.DataFrame(list(zip(safety_categories, safety_scores)), columns =['categories', 'scores'])\n",
    "    print(safety_attributes_df)\n",
    "\n",
    "    \n",
    "    composition = \"Composition: \\n\" + \", \".join(list_labels)\n",
    "    desc = response.text\n",
    "    \n",
    "    if len(language) > 1:\n",
    "        desc = translate_text(language, response.text)\n",
    "        composition = translate_text(language, composition)\n",
    "    \n",
    "    prompt_img = (ZERO_SHOT_PROMPT.replace('**PRODUCT**',search).replace('**THEMA**',theme) )\n",
    "    init_image = download_image(  image    )\n",
    "    display(init_image)\n",
    "    instances = [\n",
    "    {\n",
    "    \"prompt\": prompt_img,\n",
    "    \"image\": image_to_base64(init_image),\n",
    "    },\n",
    "    ]\n",
    "    response = endpoint.predict(instances=instances)\n",
    "    gen_images = [base64_to_image(image) for image in response.predictions]\n",
    "    display(gen_images[0])\n",
    "    images.append(gen_images[0])\n",
    "        \n",
    "    return desc, composition , images\n",
    "\n",
    "## TODO: Ajouter bannière\n",
    "# bugfix utf8\n",
    "# affichage image fleur\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "theme_demo = gr.themes.Soft(\n",
    "    secondary_hue=\"blue\",\n",
    "    font=[gr.themes.GoogleFont('Source Sans Pro'), 'ui-sans-serif', 'system-ui', 'sans-serif'],\n",
    ").set(\n",
    "    background_fill_primary='white',\n",
    "    shadow_drop='rgba(0,0,0,0.05) 0px 1px 2px 0px',\n",
    "    shadow_drop_lg='0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1)',\n",
    "    shadow_spread='3px',\n",
    "    block_background_fill='*background_fill_primary',\n",
    "    block_border_width='1px',\n",
    "    block_border_width_dark='1px',\n",
    "    block_label_background_fill='*background_fill_primary',\n",
    "    block_label_background_fill_dark='*background_fill_secondary',\n",
    "    block_label_text_color='*neutral_500',\n",
    "    block_label_text_color_dark='*neutral_200',\n",
    "    block_label_margin='0',\n",
    "    block_label_padding='*spacing_sm *spacing_lg',\n",
    "    block_label_radius='calc(*radius_lg - 1px) 0 calc(*radius_lg - 1px) 0',\n",
    "    block_label_text_size='*text_sm',\n",
    "    block_label_text_weight='400',\n",
    "    block_title_background_fill='none',\n",
    "    block_title_background_fill_dark='none',\n",
    "    block_title_text_color='*neutral_500',\n",
    "    block_title_text_color_dark='*neutral_200',\n",
    "    block_title_padding='0',\n",
    "    block_title_radius='none',\n",
    "    block_title_text_weight='400',\n",
    "    panel_border_width='0',\n",
    "    panel_border_width_dark='0',\n",
    "    checkbox_background_color_selected='*secondary_600',\n",
    "    checkbox_background_color_selected_dark='*secondary_600',\n",
    "    checkbox_border_color='*neutral_300',\n",
    "    checkbox_border_color_dark='*neutral_700',\n",
    "    checkbox_border_color_focus='*secondary_500',\n",
    "    checkbox_border_color_focus_dark='*secondary_500',\n",
    "    checkbox_border_color_selected='*secondary_600',\n",
    "    checkbox_border_color_selected_dark='*secondary_600',\n",
    "    checkbox_border_width='*input_border_width',\n",
    "    checkbox_shadow='*input_shadow',\n",
    "    checkbox_label_background_fill_selected='*checkbox_label_background_fill',\n",
    "    checkbox_label_background_fill_selected_dark='*checkbox_label_background_fill',\n",
    "    checkbox_label_shadow='none',\n",
    "    checkbox_label_text_color_selected='*checkbox_label_text_color',\n",
    "    input_background_fill='*neutral_100',\n",
    "    input_border_color='*border_color_primary',\n",
    "    input_shadow='none',\n",
    "    input_shadow_dark='none',\n",
    "    input_shadow_focus='*input_shadow',\n",
    "    input_shadow_focus_dark='*input_shadow',\n",
    "    slider_color='auto',\n",
    "    slider_color_dark='auto',\n",
    "    button_shadow='none',\n",
    "    button_shadow_active='none',\n",
    "    button_shadow_hover='none',\n",
    "    button_primary_background_fill='*primary_200',\n",
    "    button_primary_background_fill_hover='*button_primary_background_fill',\n",
    "    button_primary_background_fill_hover_dark='*button_primary_background_fill',\n",
    "    button_primary_text_color='*primary_600',\n",
    "    button_secondary_background_fill='*neutral_200',\n",
    "    button_secondary_background_fill_hover='*button_secondary_background_fill',\n",
    "    button_secondary_background_fill_hover_dark='*button_secondary_background_fill',\n",
    "    button_secondary_text_color='*neutral_700',\n",
    "    button_cancel_background_fill_hover='*button_cancel_background_fill',\n",
    "    button_cancel_background_fill_hover_dark='*button_cancel_background_fill'\n",
    ")\n",
    "\n",
    "\n",
    "#with gr.Blocks(theme=gr.themes.Default(primary_hue=gr.themes.colors.red, secondary_hue=gr.themes.colors.pink)) as demo_genretail:\n",
    "\n",
    "def Load_images(urls = [\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"]):\n",
    "    images = []    \n",
    "    for url in urls:\n",
    "        images.append(Image.open(requests.get(url , stream=True).raw))\n",
    "    return images\n",
    "\n",
    "def get_select_index(imgs_set, evt: gr.SelectData):\n",
    "    print(evt.index)\n",
    "    if(evt.index in imgs_set):\n",
    "        imgs_set.pop(imgs_set.index(evt.index))\n",
    "    else:\n",
    "        imgs_set.append(evt.index)\n",
    "    print(imgs_set)\n",
    "    return imgs_set\n",
    "\n",
    "\n",
    "    \n",
    "with gr.Blocks(theme=theme_demo) as demo_genretail:\n",
    "\n",
    "    demo_genretail.theme = theme_demo\n",
    "    \n",
    "    header = gr.HTML(html)\n",
    "#    gr.Markdown\n",
    "    md = (    \"\"\"\n",
    "\n",
    "# **Gen** ret<strong><font color=\"red\">AI</font></strong>l\n",
    "\n",
    "Customer search:\n",
    "* I search flower for **weading.**\n",
    "* I search flower for **mother day.**\n",
    "* I search flower for **valentine day.**\n",
    "\n",
    "\n",
    "Company provide:\n",
    "* I found the same product <strong><font color=\"red\">contextualized</font></strong> to my search\n",
    "    \"\"\")\n",
    "\n",
    "    image_uri = \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"\n",
    "    images = []\n",
    "  \n",
    "    images.append(Image.open(requests.get(image_uri , stream=True).raw))\n",
    "\n",
    "    #\n",
    "    \n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            search = gr.Textbox(label=\"Search a product\", placeholder=\"Try: Flower, tree, Bouquets, Roses... \")\n",
    "            theme = gr.Textbox(label=\"Thema\", placeholder=\"Try: weading, mother day, valentine days, Anniversary, Marriage, For pleasure, Congratulation, Birth...\")\n",
    "            \n",
    "            language= gr.Textbox(label=\"Description language\", placeholder=\"Try: FR, ES, NL, EN...\")\n",
    "\n",
    "            gallery_photos = gr.Gallery(\n",
    "                label=\"Generated images\", show_label=False, elem_id=\"gallery_id\"\n",
    "                ).style(columns=[2], rows=[2], object_fit=\"contain\", height=\"auto\")\n",
    "\n",
    "            gallery_photos.select(\n",
    "                get_select_index, images_selected_state, images_selected_state).then(\n",
    "                None, images_selected_state, None, _js=js_pos_select)\n",
    "\n",
    "            with gr.Accordion(\"Destination prompt advanced settings\", open=False):\n",
    "                gr.Markdown(\"Make changes to the destination prompt default settings\")\n",
    "                temperature = gr.Slider(0, 1, 0.3, label=\"temperature\")\n",
    "                top_k = gr.Slider(0, 40, 40, label=\"top_k\")\n",
    "                top_p = gr.Slider(0, 1, 1, label=\"top_p\")\n",
    "                max_output_tokens = gr.Slider(0, 1024, 700, label=\"max_output_tokens\")\n",
    "                \n",
    "                images_selected_state = gr.JSON([], visible=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with gr.Column():\n",
    "            btn = gr.Button(\"Run\")\n",
    "            product_desc_prompt_out = gr.Textbox(label=\"Product description\")\n",
    "            product_composition_prompt_out = gr.Textbox(label=\"Product composition\")\n",
    "            \n",
    "            product_images = gr.Gallery(label=\"Generated images\", show_label=False, elem_id=\"gallery\").style(columns=[3], rows=[2], object_fit=\"contain\", height=\"auto\")\n",
    "\n",
    "\n",
    "    \n",
    "    product_photo_prompt_out = \"test\"\n",
    "            \n",
    "    inputs_array = [search,\n",
    "                    theme,\n",
    "                    language,\n",
    "                    temperature,                    \n",
    "                    top_k,\n",
    "                    top_p,\n",
    "                    max_output_tokens]\n",
    "    \n",
    "    outputs_array = [product_desc_prompt_out ,\n",
    "                     product_composition_prompt_out,\n",
    "                     product_images\n",
    "                     #, product_photo_prompt_out\n",
    "#                                ,gr.Textbox(label=\"Image Generated Prompt\")\n",
    "#                         , product_images\n",
    "                         ]\n",
    "    \n",
    "    \n",
    "    demo_genretail.load(Load_images, None, gallery_photos)\n",
    "    \n",
    "\n",
    "    btn.click(fn=update, inputs=inputs_array, outputs=outputs_array )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #, examples=[\"genAI/examples/B2BDP-GALLERY-0-1.jpg\", \"examples/B2BDP-GALLERY-0-1.jpg\", \"genAI/examples/B5CL-GALLERY-0-2.jpg\"])\n",
    "    \n",
    "    \n",
    " \n",
    "demo_genretail.launch(share=True, debug=True)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    # Set debug=True in Colab for live debugging\n",
    "    # To create a public link, set `share=True` in `launch()`.\n",
    "\n",
    "#    demo_genretail.launch(share=True, debug=True)\n",
    "#     demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ec02509-82ca-4987-8ab1-b8c8e1367d43",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "! pip3 install --upgrade pip\n",
    "! pip3 install torchvision==0.14.1\n",
    "! pip3 install transformers==4.27.1\n",
    "! pip3 install diffusers==0.15.1\n",
    "! pip3 install datasets==2.9.0\n",
    "! pip3 install accelerate==0.18.0\n",
    "! pip3 install triton==2.0.0.dev20221120\n",
    "! pip3 install xformers==0.0.16\n",
    "# Install gdown for downloading example training images.\n",
    "! pip3 install gdown\n",
    "# Remove wrong cublas version.\n",
    "! pip3 uninstall nvidia_cublas_cu11 --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8042cc76-f111-4a1e-9da7-698b46e42ae9",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6308e0d3-242e-4b5d-982c-bebc39a12957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from google.cloud import aiplatform, storage\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "\n",
    "def image_to_base64(image, format=\"JPEG\"):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=format)\n",
    "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return image_str\n",
    "\n",
    "\n",
    "def base64_to_image(image_str):\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
    "    return image\n",
    "\n",
    "\n",
    "endpoint = aiplatform.Endpoint('projects/660199673046/locations/us-central1/endpoints/7168213280727498752')\n",
    "model = aiplatform.Model('projects/660199673046/locations/us-central1/models/6974081308704112640@1')\n",
    "\n",
    "\n",
    "init_image = download_image(\n",
    "    \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/slider-reassurance-2.png?context=bWFzdGVyfGltYWdlc3wxNDI1NDF8aW1hZ2UvcG5nfGltYWdlcy9oMmUvaGEzLzk1NTQxMTA4NzM2MzAucG5nfDg2YzA5Yjk0YTc5N2FkNTJkZWMyZmM1OGU4Mzc1YzIzYWYwMmZhY2ZjZThlMTQ3NjIzYWVjYTE0ODBhZDg2ZjU\"\n",
    ")\n",
    "display(init_image)\n",
    "instances = [\n",
    "    {\n",
    "        \"prompt\": \"A fantasy landscape, trending on artstation\",\n",
    "        \"image\": image_to_base64(init_image),\n",
    "    },\n",
    "]\n",
    "response = endpoint.predict(instances=instances)\n",
    "images = [base64_to_image(image) for image in response.predictions]\n",
    "display(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636271c4-528c-47fb-ac9a-7a2137feffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "URL = \"https://source.unsplash.com/random/500x500/?nature,fruit\"\n",
    "\n",
    "URL = \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"\n",
    "\n",
    "\n",
    "js_pos_select = \"\"\"\n",
    "async (images_selected_state) => {\n",
    "  const gallery = document.querySelector(\"#gallery_id\")\n",
    "  const buttons_thumbnails = gallery.querySelectorAll(\".thumbnails > button\");\n",
    "  const buttons_large = gallery.querySelectorAll(\".grid-container > button\");\n",
    "  buttons_thumbnails.forEach((btn, idx) => {\n",
    "    if(images_selected_state.includes(idx)){\n",
    "      btn.classList.add('selected-custom');\n",
    "    }else{\n",
    "      btn.classList.remove('selected-custom');\n",
    "    }\n",
    "  })\n",
    "  buttons_large.forEach((btn, idx) => {\n",
    "    if(images_selected_state.includes(idx)){\n",
    "      btn.classList.add('selected-custom');\n",
    "    }else{\n",
    "      btn.classList.remove('selected-custom');\n",
    "    }\n",
    "  })\n",
    "  return images_selected_state\n",
    "}\n",
    "\"\"\"\n",
    "css = \"\"\"\n",
    ".selected-custom {\n",
    "    --ring-color: red !important;\n",
    "    transform: scale(0.9) !important;\n",
    "    border-color: red !important;\n",
    "}\n",
    "\"\"\"\n",
    "def get_random_images(n=1):\n",
    "    images = []\n",
    "    #  for i in range(n):\n",
    "    images.append(Image.open(requests.get(URL , stream=True).raw))\n",
    "    return images\n",
    "\n",
    "def get_select_index(imgs_set, evt: gr.SelectData):\n",
    "  print(evt.index)\n",
    "  if(evt.index in imgs_set):\n",
    "    imgs_set.pop(imgs_set.index(evt.index))\n",
    "  else:\n",
    "    imgs_set.append(evt.index)\n",
    "  print(imgs_set)\n",
    "  return imgs_set\n",
    "\n",
    "with gr.Blocks(css=css) as demo:\n",
    "    images_selected_state = gr.JSON([], visible=False)\n",
    "\n",
    "    with gr.Column(variant=\"panel\"):\n",
    "        with gr.Row(variant=\"compact\"):\n",
    "            btn = gr.Button(\"Generate image\").style(full_width=False)\n",
    "\n",
    "        gallery_photos = gr.Gallery(\n",
    "            label=\"Generated images\", show_label=False, elem_id=\"gallery_id\"\n",
    "        ).style(columns=[4], rows=[2], object_fit=\"contain\", height=\"auto\")\n",
    "\n",
    "    gallery_photos.select(\n",
    "        get_select_index, images_selected_state, images_selected_state).then(\n",
    "        None, images_selected_state, None, _js=js_pos_select)\n",
    "    demo.load(get_random_images, None, gallery_photos)\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc09e25-f3f5-45f4-a2fb-a77562129080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1a7d5-850e-45e1-b57e-36f4a9c6fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492a54f-6554-473c-82b1-d396acc270b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ccec11-ecae-4059-97f4-741f13c2fdef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba19ad-c1cc-4fdf-ade4-a2f23aff4838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
