{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579aaa05-bef2-414a-8da0-b4824dbcb552",
   "metadata": {},
   "source": [
    "\n",
    "# **Gen** ret<strong><font color=\"red\">AI</font></strong>l\n",
    "\n",
    "Customer search:\n",
    "* I search flower for **weading.**\n",
    "* I search flower for **mother day.**\n",
    "* I search flower for **valentine day.**\n",
    "\n",
    "Company provide:\n",
    "* I found the same product <strong><font color=\"red\">contextualized</font></strong> to my search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301178ef-fc45-4f3e-8142-f956c84efb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZERO_SHOT_PROMPT = '''Product description **PRODUCT** according the **THEMA**\n",
    "'''\n",
    "\n",
    "ZERO_SHOT_PROMPT = '''Why this **PRODUCT** is perfect for the special event: **THEMA**\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f0a08",
   "metadata": {},
   "source": [
    "# Init project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28756a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the google cloud project id\n",
    "\n",
    "def init_gcloud_(project_id = \"ucs-fishfood-8\"):\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    # [START gae_python37_app_init_gcloud]\n",
    "    !gcloud config set project $project_id\n",
    "\n",
    "def init_project_genappbuilder():\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    init_gcloud_(project_id = \"ucs-fishfood-8\")\n",
    "\n",
    "\n",
    "def init_project_images():\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    init_gcloud_(project_id = \"cloud-llm-preview4\")\n",
    "\n",
    "\n",
    "def init_project_workstations():\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    init_gcloud_(project_id = \"cloud-workstations-demo-2\")\n",
    "\n",
    "def init_project_ml_api():\n",
    "    \"\"\"\n",
    "    Initialize the google cloud project id.\n",
    "    \"\"\"\n",
    "    init_gcloud_(project_id = \"google.com:ml-baguette-demos\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9055a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b521a34b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569f6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8665d051",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6dd21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369790e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f7983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e9fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73e012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d7f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4837996c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Image Gen (not used in the demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2c92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI SDK version: 1.25.0\n",
      "{\n",
      "  \"name\": \"projects/660199673046/locations/us-central1/operations/5344077516917178368\",\n",
      "  \"metadata\": {\n",
      "    \"@type\": \"type.googleapis.com/google.cloud.aiplatform.ui.UploadModelOperationMetadata\",\n",
      "    \"genericMetadata\": {\n",
      "      \"createTime\": \"2023-05-31T11:24:38.821446Z\",\n",
      "      \"updateTime\": \"2023-05-31T11:24:38.821446Z\",\n",
      "      \"state\": \"RUNNING\",\n",
      "      \"worksOn\": [\n",
      "        \"projects/660199673046/locations/us-central1/models/8074085517689356288@1\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"google.com:ml-baguette-demos\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "MODEL_NAME = \"text-bison@001\" # @param {type:\"string\"}\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer $(gcloud auth application-default print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "https://us-central1-aiplatform.googleapis.com/ui/projects/google.com:ml-baguette-demos/locations/us-central1/models:upload \\\n",
    "-d '{\"model\": {\"display_name\": \"vision-generative-model\",\"large_model_reference\": {\"name\": \"imagegeneration-001\"}}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5c0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "gcloud_token = !gcloud auth print-access-token\n",
    "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "\n",
    "ACCESS_TOKEN = gcloud_token[0]\n",
    "\n",
    "# This endpoint is what was available from the Private API Documentation\n",
    "# https://cloud.devsite.corp.google.com/vision-ai/docs/priv/generate-images-api\n",
    "ENDPOINT_URL = 'projects/66194518407/locations/us-central1/endpoints/4549422873969688576'\n",
    "\n",
    "# This endpoint below is from the Internal Fishfooding Guide: go/IG-fishfooding\n",
    "FF_ENDPOINT_URL = 'projects/cloud-lvm-fishfooding/locations/us-central1/endpoints/6988653136307027968'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ac4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def image_gen_model(prompt, sampleImageSize, sampleCount, endpointType='Prod', seed=None):\n",
    "  headers = {\n",
    "      'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "      'Content-Type': 'application/json; charset=UTF-8'\n",
    "  }\n",
    "  # Advanced option, try different the seed numbers\n",
    "  # any random integer number range: (0, 2147483647)\n",
    "  if seed==None:\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount}}\n",
    "  else:\n",
    "    # Use & provide a seed, if possible, so that we can reproduce the results when needed.\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount, \"seed\": seed}}\n",
    "\n",
    "  print(data)\n",
    "  if endpointType=='Prod':\n",
    "    # Prod usage\n",
    "    response = requests.post(f'https://us-central1-aiplatform.googleapis.com/v1/{ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "  else:\n",
    "    # Autopush usage\n",
    "    response = requests.post(f'https://us-central1-autopush-aiplatform.sandbox.googleapis.com/v1/{FF_ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa54adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleImageSize: 1024\n",
      "sampleCount: 6\n",
      "prompt audacious and whimsical fantasy house shaped like pasion fruit with windows and door, in the desert\n",
      "endpointType Fishfood\n",
      "seed None\n"
     ]
    }
   ],
   "source": [
    "#@title Click `Show code` in the code cell (Don't forget to run this cell). { display-mode: \"form\" }\n",
    "\n",
    "sampleImageSize = '1024' #@param {type:\"string\"}\n",
    "sampleCount = 6 #@param {type:\"integer\"}\n",
    "prompt = 'audacious and whimsical fantasy house shaped like pasion fruit with windows and door, in the desert' #@param {type:\"string\"}\n",
    "endpointType = \"Fishfood\" #@param [\"Prod\", \"Fishfood\"]\n",
    "\n",
    "# Advanced option, try different the seed numbers\n",
    "# any random integer number range: (0, 2147483647)\n",
    "seed = None #@param {type:\"raw\"}\n",
    "\n",
    "print('sampleImageSize:', sampleImageSize)\n",
    "print('sampleCount:', sampleCount)\n",
    "print('prompt', prompt)\n",
    "print('endpointType', endpointType)\n",
    "print('seed', seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e040de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': [{'prompt': 'audacious and whimsical fantasy house shaped like pasion fruit with windows and door, in the desert'}], 'parameters': {'sampleImageSize': '1024', 'sampleCount': 6}}\n",
      "An error occured calling the API.\n",
      "1. Check if response was not blocked based on policy violation, check if the UI behaves the same way...\n",
      "2. Try a different prompt to see if that was the problem.\n",
      "\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 403,\n",
      "    \"message\": \"Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/cloud-lvm-fishfooding/locations/us-central1/endpoints/6988653136307027968' (or it may not exist).\",\n",
      "    \"status\": \"PERMISSION_DENIED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\n",
      "        \"reason\": \"IAM_PERMISSION_DENIED\",\n",
      "        \"domain\": \"aiplatform.googleapis.com\",\n",
      "        \"metadata\": {\n",
      "          \"permission\": \"aiplatform.endpoints.predict\",\n",
      "          \"resource\": \"projects/cloud-lvm-fishfooding/locations/us-central1/endpoints/6988653136307027968\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use & provide a seed, if possible, so that we can reproduce the results when needed.\n",
    "response = image_gen_model(prompt, sampleImageSize, sampleCount, endpointType, seed)\n",
    "json_response = json.loads(response.text)\n",
    "\n",
    "try:\n",
    "  predictions = json_response['predictions']\n",
    "except:\n",
    "  print(\"An error occured calling the API.\")\n",
    "  print(\"1. Check if response was not blocked based on policy violation, check if the UI behaves the same way...\")\n",
    "  print(\"2. Try a different prompt to see if that was the problem.\\n\")\n",
    "  print(response.text)\n",
    "  # print(dir(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08dee8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "86c119f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def image_gen_model(prompt, sampleImageSize, sampleCount, endpointType='Prod', seed=None):\n",
    "  init_project_images()\n",
    "  gcloud_token = !gcloud auth print-access-token\n",
    "  gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "  ACCESS_TOKEN = gcloud_token[0]\n",
    "\n",
    "  # This endpoint is what was available from the Private API Documentation\n",
    "  # https://cloud.devsite.corp.google.com/vision-ai/docs/priv/generate-images-api\n",
    "  ENDPOINT_URL = 'projects/66194518407/locations/us-central1/endpoints/4549422873969688576'\n",
    "\n",
    "  # This endpoint below is from the Internal Fishfooding Guide: go/IG-fishfooding\n",
    "  #FF_ENDPOINT_URL = 'projects/cloud-lvm-fishfooding/locations/us-central1/endpoints/6988653136307027968'\n",
    "\n",
    "  headers = {\n",
    "      'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "      'Content-Type': 'application/json; charset=UTF-8'\n",
    "  }\n",
    "  # Advanced option, try different the seed numbers\n",
    "  # any random integer number range: (0, 2147483647)\n",
    "  if seed==None:\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount}}\n",
    "  else:\n",
    "    # Use & provide a seed, if possible, so that we can reproduce the results when needed.\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount, \"seed\": seed}}\n",
    "\n",
    "  print(data)\n",
    "  #if endpointType=='Prod':\n",
    "    # Prod usage\n",
    "  response = requests.post(f'https://us-central1-aiplatform.googleapis.com/v1/{ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "  #else:\n",
    "    # Autopush usage\n",
    "  #  response = requests.post(f'https://us-central1-autopush-aiplatform.sandbox.googleapis.com/v1/{FF_ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "def70516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleImageSize: 1024\n",
      "sampleCount: 6\n",
      "prompt audacious and whimsical fantasy house shaped like pasion fruit with windows and door, in the desert\n",
      "endpointType Prod\n",
      "seed None\n",
      "Updated property [core/project].\n",
      "{'instances': [{'prompt': 'audacious and whimsical fantasy house shaped like pasion fruit with windows and door, in the desert'}], 'parameters': {'sampleImageSize': '1024', 'sampleCount': 6}}\n",
      "An error occured calling the API.\n",
      "1. Check if response was not blocked based on policy violation, check if the UI behaves the same way...\n",
      "2. Try a different prompt to see if that was the problem.\n",
      "\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 403,\n",
      "    \"message\": \"Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/66194518407/locations/us-central1/endpoints/4549422873969688576' (or it may not exist).\",\n",
      "    \"status\": \"PERMISSION_DENIED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\n",
      "        \"reason\": \"IAM_PERMISSION_DENIED\",\n",
      "        \"domain\": \"aiplatform.googleapis.com\",\n",
      "        \"metadata\": {\n",
      "          \"permission\": \"aiplatform.endpoints.predict\",\n",
      "          \"resource\": \"projects/66194518407/locations/us-central1/endpoints/4549422873969688576\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Click `Show code` in the code cell (Don't forget to run this cell). { display-mode: \"form\" }\n",
    "\n",
    "sampleImageSize = '1024' #@param {type:\"string\"}\n",
    "sampleCount = 6 #@param {type:\"integer\"}\n",
    "prompt = 'audacious and whimsical fantasy house shaped like pasion fruit with windows and door, in the desert' #@param {type:\"string\"}\n",
    "endpointType = \"Prod\" #@param [\"Prod\", \"Fishfood\"]\n",
    "\n",
    "# Advanced option, try different the seed numbers\n",
    "# any random integer number range: (0, 2147483647)\n",
    "seed = None #@param {type:\"raw\"}\n",
    "\n",
    "print('sampleImageSize:', sampleImageSize)\n",
    "print('sampleCount:', sampleCount)\n",
    "print('prompt', prompt)\n",
    "print('endpointType', endpointType)\n",
    "print('seed', seed)\n",
    "\n",
    "# Use & provide a seed, if possible, so that we can reproduce the results when needed.\n",
    "response = image_gen_model(prompt, sampleImageSize, sampleCount, endpointType, seed)\n",
    "json_response = json.loads(response.text)\n",
    "\n",
    "try:\n",
    "  predictions = json_response['predictions']\n",
    "except:\n",
    "  print(\"An error occured calling the API.\")\n",
    "  print(\"1. Check if response was not blocked based on policy violation, check if the UI behaves the same way...\")\n",
    "  print(\"2. Try a different prompt to see if that was the problem.\\n\")\n",
    "  print(response.text)\n",
    "  # print(dir(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da2447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e70b118",
   "metadata": {},
   "source": [
    "# Palm LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d718b7-5c0a-47a2-825f-ed6e4b49255e",
   "metadata": {},
   "source": [
    "#### The `top_k` parameter (range: 0.0 - 40, default 40)\n",
    "\n",
    "##### What is _top_k_?\n",
    "`top_k` changes how the model selects tokens for output. A `top_k` of 1 means the selected token is the most probable among all tokens in the model's vocabulary (also called greedy decoding). In contrast, a `top_k` of 3 means that the next token is selected from the top 3 most probable tokens (using temperature). For each token selection step, the `top_k` tokens with the highest probabilities are sampled. Then tokens are further filtered based on `top_p` with the final token selected using temperature sampling.\n",
    "\n",
    "##### How does _top_k_ affect the response?\n",
    "\n",
    "Specify a lower value for less random responses and a higher value for more random responses.\n",
    "\n",
    "For more information on the `top_k` parameter for text models, please refer to the [documentation on model parameters](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models#text_model_parameters).\n",
    "                                                                                                                       \n",
    "#### The `top_p` parameter (range: 0.0 - 1.0, default 0.95)\n",
    "                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74be919-0249-48f6-8e18-fac317201e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roses are a classic flower for weddings, and for good reason. They are beautiful, elegant, and symbolize love, romance, and commitment. Roses come in a variety of colors, so you can choose the perfect shade to match your wedding theme. You can also choose roses in different sizes, shapes, and arrangements to create a unique and personalized bouquet."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel,\\\n",
    "                                            ChatModel,\\\n",
    "                                            InputOutputTextPair,\\\n",
    "                                            TextEmbeddingModel\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "\n",
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "\n",
    "\n",
    "def generative_example(text_input, temperature=0.6, top_k=40, top_p=0.9, max_output_tokens=512):\n",
    "    \"\"\"Text Generation with a Large Language Model.\"\"\"\n",
    "    response = generation_model.predict(\n",
    "        text_input,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k, # default top_k=1\n",
    "        top_p=top_p, # default top_p=0\n",
    "        max_output_tokens=max_output_tokens, # default 32\n",
    "    )\n",
    "    #print(response.text)\n",
    "    \n",
    "    return response\n",
    "\n",
    "generative_example(ZERO_SHOT_PROMPT.replace('**PRODUCT**',\"flower\").replace('**THEMA**',\"weading\") )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d2f21f",
   "metadata": {},
   "source": [
    "# Cloud vision to enrich text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216c60af-d22e-4944-b42b-30f7fe65588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from google.cloud import vision\n",
    "\n",
    "\n",
    "def analyze_image_from_uri(\n",
    "    image_uri: str,\n",
    "    feature_types: Sequence,\n",
    ") -> vision.AnnotateImageResponse:\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = image_uri\n",
    "    features = [vision.Feature(type_=feature_type) for feature_type in feature_types]\n",
    "    request = vision.AnnotateImageRequest(image=image, features=features)\n",
    "\n",
    "    response = client.annotate_image(request=request)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def print_labels(response: vision.AnnotateImageResponse):\n",
    "    print(\"LABELS \" +\"==\" * 80)\n",
    "    for label in response.label_annotations:\n",
    "        print(\n",
    "            f\"{label.score:4.0%}\",\n",
    "            f\"{label.description:5}\",\n",
    "            sep=\" | \",\n",
    "        )\n",
    "    return response.label_annotations\n",
    "\n",
    "def print_text(response: vision.AnnotateImageResponse):\n",
    "    print(\"TEXT \"+\"==\" * 80)\n",
    "    for annotation in response.text_annotations:\n",
    "        vertices = [f\"({v.x},{v.y})\" for v in annotation.bounding_poly.vertices]\n",
    "        print(\n",
    "            f\"{repr(annotation.description):42}\",\n",
    "            \",\".join(vertices),\n",
    "            sep=\" | \",\n",
    "        )\n",
    "        \n",
    "def print_landmarks(response: vision.AnnotateImageResponse, min_score: float = 0.5):\n",
    "    print(\"LANDMARKS \" +\"==\" * 80)\n",
    "    for landmark in response.landmark_annotations:\n",
    "        if landmark.score < min_score:\n",
    "            continue\n",
    "        vertices = [f\"({v.x},{v.y})\" for v in landmark.bounding_poly.vertices]\n",
    "        lat_lng = landmark.locations[0].lat_lng\n",
    "        print(\n",
    "            f\"{landmark.description:18}\",\n",
    "            \",\".join(vertices),\n",
    "            f\"{lat_lng.latitude:.5f}\",\n",
    "            f\"{lat_lng.longitude:.5f}\",\n",
    "            sep=\" | \",\n",
    "        )       \n",
    "\n",
    "def print_objects(response: vision.AnnotateImageResponse):\n",
    "    print(\"OBJECTS \" +\"==\" * 80)\n",
    "    for obj in response.localized_object_annotations:\n",
    "        nvertices = obj.bounding_poly.normalized_vertices\n",
    "        print(\n",
    "            f\"{obj.score:4.0%}\",\n",
    "            f\"{obj.name:15}\",\n",
    "            f\"{obj.mid:10}\",\n",
    "            \",\".join(f\"({v.x:.1f},{v.y:.1f})\" for v in nvertices),\n",
    "            sep=\" | \",\n",
    "        )   \n",
    "\n",
    "def print_logos(response: vision.AnnotateImageResponse, min_score: float = 0.5):\n",
    "    print(\"LOGO \"+\"==\" * 80)\n",
    "\n",
    "    for logo in response.logo_annotations:\n",
    "        if logo.score < min_score:\n",
    "            continue\n",
    "        \n",
    "        print('Logos:')\n",
    "        print(logo.description)\n",
    "    \n",
    "def print_safe(response: vision.AnnotateImageResponse):\n",
    "    print(\"SAFE \"+\"==\" * 80)\n",
    "\n",
    "    safe = response.safe_search_annotation\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    print('Safe search:')\n",
    "\n",
    "    print(f'adult: {likelihood_name[safe.adult]}')\n",
    "    print(f'medical: {likelihood_name[safe.medical]}')\n",
    "    print(f'spoofed: {likelihood_name[safe.spoof]}')\n",
    "    print(f'violence: {likelihood_name[safe.violence]}')\n",
    "    print(f'racy: {likelihood_name[safe.racy]}')\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))    \n",
    "    \n",
    "\n",
    "def print_web(response: vision.AnnotateImageResponse):\n",
    "    print(\"WEB \"+\"==\" * 80)\n",
    "\n",
    "    annotations = response.web_detection\n",
    "\n",
    "    if annotations.best_guess_labels:\n",
    "        for label in annotations.best_guess_labels:\n",
    "            print(f'\\nBest guess label: {label.label}')\n",
    "\n",
    "    if annotations.pages_with_matching_images:\n",
    "        print('\\n{} Pages with matching images found:'.format(\n",
    "            len(annotations.pages_with_matching_images)))\n",
    "\n",
    "        for page in annotations.pages_with_matching_images:\n",
    "            print(f'\\n\\tPage url   : {page.url}')\n",
    "\n",
    "            if page.full_matching_images:\n",
    "                print('\\t{} Full Matches found: '.format(\n",
    "                       len(page.full_matching_images)))\n",
    "\n",
    "                for image in page.full_matching_images:\n",
    "                    print(f'\\t\\tImage url  : {image.url}')\n",
    "\n",
    "            if page.partial_matching_images:\n",
    "                print('\\t{} Partial Matches found: '.format(\n",
    "                       len(page.partial_matching_images)))\n",
    "\n",
    "                for image in page.partial_matching_images:\n",
    "                    print(f'\\t\\tImage url  : {image.url}')\n",
    "\n",
    "    if annotations.web_entities:\n",
    "        print('\\n{} Web entities found: '.format(\n",
    "            len(annotations.web_entities)))\n",
    "\n",
    "        for entity in annotations.web_entities:\n",
    "            print(f'\\n\\tScore      : {entity.score}')\n",
    "            print(f'\\tDescription: {entity.description}')\n",
    "\n",
    "    if annotations.visually_similar_images:\n",
    "        print('\\n{} visually similar images found:\\n'.format(\n",
    "            len(annotations.visually_similar_images)))\n",
    "\n",
    "        for image in annotations.visually_similar_images:\n",
    "            print(f'\\tImage url    : {image.url}')\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f41abb4-88b7-4994-838b-612b8bccb613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELS ================================================================================================================================================================\n",
      " 98% | Flower\n",
      " 95% | Plant\n",
      " 92% | Vase \n",
      " 92% | Flowerpot\n",
      " 91% | Petal\n",
      " 83% | Hybrid tea rose\n",
      " 83% | Creative arts\n",
      " 83% | Pink \n",
      " 80% | Rose \n",
      " 79% | Flower Arranging\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Flower',\n",
       " 'Plant',\n",
       " 'Vase',\n",
       " 'Flowerpot',\n",
       " 'Petal',\n",
       " 'Hybrid tea rose',\n",
       " 'Creative arts',\n",
       " 'Pink']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_labels (\n",
    "image_uri = \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"\n",
    "):\n",
    "    features = [vision.Feature.Type.LABEL_DETECTION, \n",
    "                vision.Feature.Type.LANDMARK_DETECTION, \n",
    "                vision.Feature.Type.LOGO_DETECTION,\n",
    "    #            vision.Feature.Type.SAFE_SEARCH_DETECTION,\n",
    "                vision.Feature.Type.WEB_DETECTION,\n",
    "                vision.Feature.Type.TEXT_DETECTION,\n",
    "                vision.Feature.Type.OBJECT_LOCALIZATION]\n",
    "\n",
    "    features = [vision.Feature.Type.LABEL_DETECTION] \n",
    "\n",
    "    response = analyze_image_from_uri(image_uri, features)\n",
    "    labels = print_labels(response)\n",
    "    list_labels = [x.description for x in list(filter(lambda x: (x.score > 0.80 ), labels)) ]\n",
    "\n",
    "    return list_labels\n",
    "\n",
    "image_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d12c8-c9cd-495e-983d-4213c8b3697a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f6b0fe2",
   "metadata": {},
   "source": [
    "# Translate API to support multiple input/output languages (only english is supported by Palm actually)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9a8fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-translate==2.0.1 in /opt/conda/lib/python3.7/site-packages (2.0.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-translate==2.0.1) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-translate==2.0.1) (1.7.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (1.56.4)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (3.20.3)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (1.35.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (2.28.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (1.48.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (1.48.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.1.0->google-cloud-translate==2.0.1) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (0.2.7)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (67.7.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1) (0.4.8)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-translate==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91146c7-110c-42c5-9f5c-3da2d2bae1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Text: The tree is perfect for the special event: wedding because it is covered in beautiful pink flowers. The flowers are a symbol of love and romance, and they make the tree look very elegant and festive. The tree would be a beautiful addition to any wedding ceremony or reception, and it would make a lasting impression on guests.\n",
      "Translation: L&#39;arbre est parfait pour l&#39;événement spécial : mariage car il est couvert de belles fleurs roses. Les fleurs sont un symbole d&#39;amour et de romance, et elles donnent à l&#39;arbre un aspect très élégant et festif. L&#39;arbre serait un bel ajout à toute cérémonie de mariage ou réception, et il ferait une impression durable sur les invités.\n",
      "Detected source language: en\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"L'arbre est parfait pour l'événement spécial : mariage car il est couvert de belles fleurs roses. Les fleurs sont un symbole d'amour et de romance, et elles donnent à l'arbre un aspect très élégant et festif. L'arbre serait un bel ajout à toute cérémonie de mariage ou réception, et il ferait une impression durable sur les invités.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_text(target, text):\n",
    "\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "\n",
    "    print(\"Text: {}\".format(result[\"input\"]))\n",
    "    print(\"Translation: {}\".format(result[\"translatedText\"]))\n",
    "    print(\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
    "    \n",
    "    if isinstance(result[\"translatedText\"], bytes):\n",
    "        print(\"bytes\")\n",
    "        text = result[\"translatedText\"].decode(\"utf-8\")\n",
    "        return text\n",
    "        \n",
    "    unicode_string = result[\"translatedText\"]\n",
    "    \n",
    "    return clean_text(unicode_string)\n",
    "    \n",
    "# TODO: Clean me ugly code\n",
    "def clean_text(s : str):    \n",
    "    return s.replace(\"&#39;\", \"'\")\n",
    "\n",
    "init_project_ml_api()\n",
    "translate_text( \"FR\", \"The tree is perfect for the special event: wedding because it is covered in beautiful pink flowers. The flowers are a symbol of love and romance, and they make the tree look very elegant and festive. The tree would be a beautiful addition to any wedding ceremony or reception, and it would make a lasting impression on guests.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643409f7-d88a-402d-a036-39102027137a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6818c-ea68-4ddd-abed-697cd7617318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94d23387",
   "metadata": {},
   "source": [
    "# gradio interface used by the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "840d0dec-7a5c-411b-8b60-4d09431831a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gradio in /home/jupyter/.local/lib/python3.7/site-packages (3.28.0)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/lib/python3.7/site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: altair>=4.2.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.7/site-packages (from gradio) (0.95.1)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.7/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: gradio-client>=0.1.3 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (0.1.4)\n",
      "Requirement already satisfied: httpx in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (0.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (0.13.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.7/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from gradio) (3.5.3)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /opt/conda/lib/python3.7/site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from gradio) (1.21.6)\n",
      "Requirement already satisfied: orjson in /opt/conda/lib/python3.7/site-packages (from gradio) (3.8.11)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from gradio) (1.3.5)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from gradio) (9.5.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from gradio) (1.10.7)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.7/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /opt/conda/lib/python3.7/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gradio) (2.28.2)\n",
      "Requirement already satisfied: semantic-version in /opt/conda/lib/python3.7/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from gradio) (4.5.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.7/site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (11.0.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from gradio-client>=0.1.3->gradio) (2023.1.0)\n",
      "Requirement already satisfied: packaging in /home/jupyter/.local/lib/python3.7/site-packages (from gradio-client>=0.1.3->gradio) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio) (4.11.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /home/jupyter/.local/lib/python3.7/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (0.13.0)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /opt/conda/lib/python3.7/site-packages (from fastapi->gradio) (0.26.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/jupyter/.local/lib/python3.7/site-packages (from httpx->gradio) (0.17.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gradio) (1.26.15)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from uvicorn->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.1)\n",
      "Requirement already satisfied: uc-micro-py in /opt/conda/lib/python3.7/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.13.0->gradio) (3.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "362b1d78-4e61-4f6a-bf48-cbda6a61bf40",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <h1>My First JavaScript</h1>\n",
    "    <button type=\"testButton\" onclick=\"testFn()\"> Start </button>\n",
    "    \n",
    "    <p id=\"demo\"></p>\n",
    "    \n",
    "    <!-- Element that opens the widget on click. It does not have to be an input -->\n",
    "    <input placeholder=\"Search here\" id=\"searchWidgetTrigger\" />\n",
    "\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "scripts = \"\"\"\n",
    "async () => {\n",
    "   // set testFn() function on globalThis, so you html onlclick can access it\n",
    "    globalThis.testFn = () => {\n",
    "      document.getElementById('demo').innerHTML = \"Hello\"\n",
    "    }\n",
    "\n",
    "\n",
    "<!-- Gen App Builder widget bundle -->\n",
    "<script src=\"https://gen-ai-app-builder.appspot.com/preview/client\"></script>\n",
    "\n",
    "<!-- Search widget element is not visible by default -->\n",
    "<gen-search-widget\n",
    "  widgetConfigName=\"projects/210552312048/locations/global/collections/default_collection/dataStores/interflora_website/widgetConfigs/default_search_widget_config\"\n",
    "  apiKey=\"AIzaSyALVFMY1VdfXHWrtx-o1uiAcHyeKq_8N5U\"\n",
    "  triggerId=\"searchWidgetTrigger\">\n",
    "</gen-search-widget>\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks() as demo1:   \n",
    "    input_mic = gr.HTML(html)\n",
    "    out_text  = gr.Textbox()\n",
    "    # run script function on load,\n",
    "    demo1.load(None,None,None,_js=scripts)\n",
    "\n",
    "   \n",
    "demo1.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4d77c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48777403-3039-4054-8644-bf1e0e023325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting gradio==3.24\n",
      "  Downloading gradio-3.24.0-py3-none-any.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiofiles in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (3.8.3)\n",
      "Requirement already satisfied: altair>=4.2.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio==3.24) (4.2.2)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (0.95.1)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (0.3.0)\n",
      "Requirement already satisfied: gradio-client>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (0.2.5)\n",
      "Requirement already satisfied: httpx in /home/jupyter/.local/lib/python3.7/site-packages (from gradio==3.24) (0.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio==3.24) (0.13.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (3.5.3)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (0.3.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (1.21.6)\n",
      "Requirement already satisfied: orjson in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (3.8.11)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (1.3.5)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (9.5.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (1.10.7)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (0.0.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (2.28.2)\n",
      "Requirement already satisfied: semantic-version in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (4.5.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.7/site-packages (from gradio==3.24) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio==3.24) (11.0.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio==3.24) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio==3.24) (4.17.3)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio==3.24) (0.12.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from gradio-client>=0.0.5->gradio==3.24) (2023.1.0)\n",
      "Requirement already satisfied: packaging in /home/jupyter/.local/lib/python3.7/site-packages (from gradio-client>=0.0.5->gradio==3.24) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio==3.24) (3.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio==3.24) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio==3.24) (4.11.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.24) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /home/jupyter/.local/lib/python3.7/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.24) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio==3.24) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio==3.24) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.24) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.24) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.24) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.24) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.24) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.24) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.24) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.24) (0.13.0)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /opt/conda/lib/python3.7/site-packages (from fastapi->gradio==3.24) (0.26.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from httpx->gradio==3.24) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/jupyter/.local/lib/python3.7/site-packages (from httpx->gradio==3.24) (0.17.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from httpx->gradio==3.24) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from httpx->gradio==3.24) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio==3.24) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio==3.24) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio==3.24) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio==3.24) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gradio==3.24) (1.26.15)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from uvicorn->gradio==3.24) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn->gradio==3.24) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.24) (3.6.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.24) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.24) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.24) (0.18.1)\n",
      "Requirement already satisfied: uc-micro-py in /opt/conda/lib/python3.7/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.24) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->gradio==3.24) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.13.0->gradio==3.24) (3.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: gradio\n",
      "  Attempting uninstall: gradio\n",
      "    Found existing installation: gradio 3.32.0\n",
      "    Uninstalling gradio-3.32.0:\n",
      "      Successfully uninstalled gradio-3.32.0\n",
      "Successfully installed gradio-3.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio==3.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7624814c-2e7d-4ec0-8c8d-2c365a95cd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gradio in /opt/conda/lib/python3.7/site-packages (3.24.0)\n",
      "Collecting gradio\n",
      "  Using cached gradio-3.32.0-py3-none-any.whl (19.9 MB)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/lib/python3.7/site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: altair>=4.2.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.7/site-packages (from gradio) (0.95.1)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.7/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: gradio-client>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from gradio) (0.2.5)\n",
      "Requirement already satisfied: httpx in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (0.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (0.13.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.7/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from gradio) (3.5.3)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /opt/conda/lib/python3.7/site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from gradio) (1.21.6)\n",
      "Requirement already satisfied: orjson in /opt/conda/lib/python3.7/site-packages (from gradio) (3.8.11)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from gradio) (1.3.5)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from gradio) (9.5.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from gradio) (1.10.7)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.7/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.7/site-packages (from gradio) (2.15.1)\n",
      "Requirement already satisfied: python-multipart in /opt/conda/lib/python3.7/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gradio) (2.28.2)\n",
      "Requirement already satisfied: semantic-version in /opt/conda/lib/python3.7/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from gradio) (4.5.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /home/jupyter/.local/lib/python3.7/site-packages (from gradio) (11.0.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from gradio-client>=0.2.4->gradio) (2023.1.0)\n",
      "Requirement already satisfied: packaging in /home/jupyter/.local/lib/python3.7/site-packages (from gradio-client>=0.2.4->gradio) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.13.0->gradio) (4.11.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /home/jupyter/.local/lib/python3.7/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio) (2023.3)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio) (0.13.0)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /opt/conda/lib/python3.7/site-packages (from fastapi->gradio) (0.26.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/jupyter/.local/lib/python3.7/site-packages (from httpx->gradio) (0.17.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gradio) (1.26.15)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.1)\n",
      "Requirement already satisfied: uc-micro-py in /opt/conda/lib/python3.7/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.13.0->gradio) (3.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: gradio\n",
      "\u001b[33m  WARNING: The scripts gradio and upload_theme are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed gradio-3.32.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02b6774f-09c8-4d62-9c85-6d5dcabb6b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://c5c9fecc7e8a479b1e.gradio.live ✔\n",
      "Client.predict() Usage Info\n",
      "---------------------------\n",
      "Named API endpoints: 0\n",
      "\n",
      "Unnamed API endpoints: 1\n",
      "\n",
      " - predict(query, fn_index=0) -> (title, link, snippet, description, image)\n",
      "    Parameters:\n",
      "     - [Textbox] query: str \n",
      "    Returns:\n",
      "     - [Textbox] title: str \n",
      "     - [Textbox] link: str \n",
      "     - [Textbox] snippet: str \n",
      "     - [Textbox] description: str \n",
      "     - [Textbox] image: str \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Fleurs Deuil - Livraison fleurs décès, deuil, enterrement',\n",
       " 'https://www.interflora.fr/c/fleurs-deuil',\n",
       " 'Livraison de fleurs pour deuil, enterrement | Livraison sur tombe ou sur lieu de cérémonie en - de 4h | Qualité garantie : Bouquet réalisé par un artisan\\xa0...',\n",
       " 'Livraison de fleurs pour deuil, enterrement | Livraison sur tombe ou sur lieu de cérémonie en - de 4h | Qualité garantie : Bouquet réalisé par un artisan fleuriste',\n",
       " 'https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/6INT-THUMBMAY-PRIMARY-0-1.png?context=bWFzdGVyfGltYWdlc3wzNDk1MDN8aW1hZ2UvcG5nfGltYWdlcy9oZTYvaDU5Lzk0Njg0MjQ4ODAxNTgucG5nfGFkOGQwMTc5NjQzNmZjNDM0MmFhY2Q4MjBmZWI3YzI3N2UwNTg4OGNjNGI4OTZhM2JjZmI5MDNmNTBmYmFjMDM')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "genappbuilder_demo_url = \"https://c5c9fecc7e8a479b1e.gradio.live\"\n",
    "client_genappbuilder = Client(genappbuilder_demo_url)\n",
    "\n",
    "client_genappbuilder.view_api()\n",
    "\n",
    "client_genappbuilder.predict(\"fleur\",  fn_index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d4aee9-f0b2-4775-81b1-fda66e7e4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<div class=\"PushMomentsFirst-picture\"><picture class=\"BlockPicture BlockResizePicture\"><source srcset=\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/Bandeau-principal-MothersDay2023-Octopus-02.jpg?frz-width=640&amp;frz-height=450&amp;frz-gravity=center&amp;frz-enlarge=true&amp;context=bWFzdGVyfHJvb3R8MjIwMjIwfGltYWdlL2pwZWd8aGIwL2gzZC85NTc5NzE5OTgzMTM0LmpwZ3wxMDg1YjM1Y2E0NDkzMDk1NWRhMTg0ODViNWU5YzBlYTk2OTk2ZDI3OTE5ODc2MjNiY2M3NDMyYmZjNTdjMGJl 1x\" media=\"(max-width: 639px)\"><source srcset=\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/Bandeau-principal-MothersDay2023-Octopus-02.jpg?frz-width=959&amp;frz-height=450&amp;frz-gravity=center&amp;frz-enlarge=true&amp;context=bWFzdGVyfHJvb3R8MjIwMjIwfGltYWdlL2pwZWd8aGIwL2gzZC85NTc5NzE5OTgzMTM0LmpwZ3wxMDg1YjM1Y2E0NDkzMDk1NWRhMTg0ODViNWU5YzBlYTk2OTk2ZDI3OTE5ODc2MjNiY2M3NDMyYmZjNTdjMGJl 1x\" media=\"(max-width: 959px)\"><source srcset=\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/Bandeau-principal-MothersDay2023-Octopus-02.jpg?frz-width=1600&amp;frz-height=450&amp;frz-gravity=center&amp;frz-enlarge=true&amp;context=bWFzdGVyfHJvb3R8MjIwMjIwfGltYWdlL2pwZWd8aGIwL2gzZC85NTc5NzE5OTgzMTM0LmpwZ3wxMDg1YjM1Y2E0NDkzMDk1NWRhMTg0ODViNWU5YzBlYTk2OTk2ZDI3OTE5ODc2MjNiY2M3NDMyYmZjNTdjMGJl 1x\" media=\"(min-width: 960px)\"> <img src=\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/Bandeau-principal-MothersDay2023-Octopus-02.jpg?context=bWFzdGVyfHJvb3R8MjIwMjIwfGltYWdlL2pwZWd8aGIwL2gzZC85NTc5NzE5OTgzMTM0LmpwZ3wxMDg1YjM1Y2E0NDkzMDk1NWRhMTg0ODViNWU5YzBlYTk2OTk2ZDI3OTE5ODc2MjNiY2M3NDMyYmZjNTdjMGJl\" alt=\"Fête des Mères Dimanche 4 juin\" width=\"480\" height=\"480\" fetchpriority=\"high\"></picture></div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbda468a-356f-47a0-8835-670aa76e012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7875\n",
      "Running on public URL: https://ead153f79c12eeecca.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ead153f79c12eeecca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "375",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2274/4139637536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m \u001b[0mdemo_genretail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;31m#if __name__ == \"__main__\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, file_directories, allowed_paths, blocked_paths, root_path, _frontend, app_kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m             }\n\u001b[0;32m-> 1932\u001b[0;31m             \u001b[0manalytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunched_analytics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_tip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gradio/analytics.py\u001b[0m in \u001b[0;36mlaunched_analytics\u001b[0;34m(blocks, data)\u001b[0m\n\u001b[1;32m    118\u001b[0m         ]\n\u001b[1;32m    119\u001b[0m         inputs_telemetry = inputs_telemetry + [\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         ]\n\u001b[1;32m    122\u001b[0m         outputs_telemetry = outputs_telemetry + [\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gradio/analytics.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    118\u001b[0m         ]\n\u001b[1;32m    119\u001b[0m         inputs_telemetry = inputs_telemetry + [\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         ]\n\u001b[1;32m    122\u001b[0m         outputs_telemetry = outputs_telemetry + [\n",
      "\u001b[0;31mKeyError\u001b[0m: 375"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import base64\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "\n",
    "gcloud_token = !gcloud auth print-access-token\n",
    "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "\n",
    "ACCESS_TOKEN = gcloud_token[0]\n",
    "\n",
    "endpointType = \"Prod\" #@param [\"Prod\", \"Fishfood\"]\n",
    "seed=0\n",
    "\n",
    "def update(search,\n",
    "           theme,\n",
    "           language,\n",
    "           temperature,\n",
    "           top_k,\n",
    "           top_p,\n",
    "           max_output_tokens,\n",
    "           endpointType='Prod' #,           seed=None\n",
    "          ):\n",
    "    \n",
    "    title, link, snippet, description, image = client_genappbuilder.predict(search,  fn_index=0)\n",
    "    print(\"Title: \", title)\n",
    "    print(\"Link: \", link)\n",
    "    print(\"Description: \", description)\n",
    "    print(\"Snippet: \", snippet)\n",
    "    print(\"Image: \", image)\n",
    "    \n",
    "    images = []\n",
    "  \n",
    "    images.append(Image.open(requests.get(image , stream=True).raw))\n",
    "\n",
    "    #image_uri = \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"\n",
    "\n",
    "    list_labels = image_labels(image)\n",
    "    prompt = (ZERO_SHOT_PROMPT.replace('**PRODUCT**',search).replace('**THEMA**',theme) + \" with the labels: \"+ \", \".join(list_labels))\n",
    "    \n",
    "    \n",
    "    print(prompt)\n",
    "    print(temperature)\n",
    "    print(float(temperature))\n",
    "    response = generative_example(prompt, temperature=float(temperature), top_k=top_k, top_p=top_p, max_output_tokens=max_output_tokens)\n",
    "\n",
    "    print(response.text)\n",
    "    \n",
    "    if response._prediction_response[0][0]['safetyAttributes']['blocked'] == True:\n",
    "        print(\"Function not available\")\n",
    "    else:\n",
    "        print(\"LLM answer: \\n\",response.text)    \n",
    "\n",
    "    import pandas as pd\n",
    "    safety_categories = response._prediction_response[0][0]['safetyAttributes']['categories']\n",
    "    safety_scores = response._prediction_response[0][0]['safetyAttributes']['scores']\n",
    "    safety_blocked = response._prediction_response[0][0]['safetyAttributes']['blocked']\n",
    "\n",
    "    safety_attributes_df = pd.DataFrame(list(zip(safety_categories, safety_scores)), columns =['categories', 'scores'])\n",
    "    print(safety_attributes_df)\n",
    "\n",
    "    \n",
    "    if len(language) > 1:\n",
    "        desc = translate_text(language, response.text)\n",
    "    else:\n",
    "        desc = response.text\n",
    "\n",
    "    return desc, \"composition:\" + \", \".join(list_labels) , images\n",
    "\n",
    "## TODO: Ajouter bannière\n",
    "# bugfix utf8\n",
    "# affichage image fleur\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "theme_demo = gr.themes.Soft(\n",
    "    secondary_hue=\"blue\",\n",
    "    font=[gr.themes.GoogleFont('Source Sans Pro'), 'ui-sans-serif', 'system-ui', 'sans-serif'],\n",
    ").set(\n",
    "    background_fill_primary='white',\n",
    "    shadow_drop='rgba(0,0,0,0.05) 0px 1px 2px 0px',\n",
    "    shadow_drop_lg='0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1)',\n",
    "    shadow_spread='3px',\n",
    "    block_background_fill='*background_fill_primary',\n",
    "    block_border_width='1px',\n",
    "    block_border_width_dark='1px',\n",
    "    block_label_background_fill='*background_fill_primary',\n",
    "    block_label_background_fill_dark='*background_fill_secondary',\n",
    "    block_label_text_color='*neutral_500',\n",
    "    block_label_text_color_dark='*neutral_200',\n",
    "    block_label_margin='0',\n",
    "    block_label_padding='*spacing_sm *spacing_lg',\n",
    "    block_label_radius='calc(*radius_lg - 1px) 0 calc(*radius_lg - 1px) 0',\n",
    "    block_label_text_size='*text_sm',\n",
    "    block_label_text_weight='400',\n",
    "    block_title_background_fill='none',\n",
    "    block_title_background_fill_dark='none',\n",
    "    block_title_text_color='*neutral_500',\n",
    "    block_title_text_color_dark='*neutral_200',\n",
    "    block_title_padding='0',\n",
    "    block_title_radius='none',\n",
    "    block_title_text_weight='400',\n",
    "    panel_border_width='0',\n",
    "    panel_border_width_dark='0',\n",
    "    checkbox_background_color_selected='*secondary_600',\n",
    "    checkbox_background_color_selected_dark='*secondary_600',\n",
    "    checkbox_border_color='*neutral_300',\n",
    "    checkbox_border_color_dark='*neutral_700',\n",
    "    checkbox_border_color_focus='*secondary_500',\n",
    "    checkbox_border_color_focus_dark='*secondary_500',\n",
    "    checkbox_border_color_selected='*secondary_600',\n",
    "    checkbox_border_color_selected_dark='*secondary_600',\n",
    "    checkbox_border_width='*input_border_width',\n",
    "    checkbox_shadow='*input_shadow',\n",
    "    checkbox_label_background_fill_selected='*checkbox_label_background_fill',\n",
    "    checkbox_label_background_fill_selected_dark='*checkbox_label_background_fill',\n",
    "    checkbox_label_shadow='none',\n",
    "    checkbox_label_text_color_selected='*checkbox_label_text_color',\n",
    "    input_background_fill='*neutral_100',\n",
    "    input_border_color='*border_color_primary',\n",
    "    input_shadow='none',\n",
    "    input_shadow_dark='none',\n",
    "    input_shadow_focus='*input_shadow',\n",
    "    input_shadow_focus_dark='*input_shadow',\n",
    "    slider_color='auto',\n",
    "    slider_color_dark='auto',\n",
    "    button_shadow='none',\n",
    "    button_shadow_active='none',\n",
    "    button_shadow_hover='none',\n",
    "    button_primary_background_fill='*primary_200',\n",
    "    button_primary_background_fill_hover='*button_primary_background_fill',\n",
    "    button_primary_background_fill_hover_dark='*button_primary_background_fill',\n",
    "    button_primary_text_color='*primary_600',\n",
    "    button_secondary_background_fill='*neutral_200',\n",
    "    button_secondary_background_fill_hover='*button_secondary_background_fill',\n",
    "    button_secondary_background_fill_hover_dark='*button_secondary_background_fill',\n",
    "    button_secondary_text_color='*neutral_700',\n",
    "    button_cancel_background_fill_hover='*button_cancel_background_fill',\n",
    "    button_cancel_background_fill_hover_dark='*button_cancel_background_fill'\n",
    ")\n",
    "\n",
    "\n",
    "#with gr.Blocks(theme=gr.themes.Default(primary_hue=gr.themes.colors.red, secondary_hue=gr.themes.colors.pink)) as demo_genretail:\n",
    "\n",
    "def Load_images(urls = [\"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"]):\n",
    "    images = []    \n",
    "    for url in urls:\n",
    "        images.append(Image.open(requests.get(url , stream=True).raw))\n",
    "    return images\n",
    "\n",
    "def get_select_index(imgs_set, evt: gr.SelectData):\n",
    "    print(evt.index)\n",
    "    if(evt.index in imgs_set):\n",
    "        imgs_set.pop(imgs_set.index(evt.index))\n",
    "    else:\n",
    "        imgs_set.append(evt.index)\n",
    "    print(imgs_set)\n",
    "    return imgs_set\n",
    "\n",
    "\n",
    "    \n",
    "with gr.Blocks(theme=theme_demo) as demo_genretail:\n",
    "\n",
    "    demo_genretail.theme = theme_demo\n",
    "    \n",
    "    header = gr.HTML(html)\n",
    "#    gr.Markdown\n",
    "    md = (    \"\"\"\n",
    "\n",
    "# **Gen** ret<strong><font color=\"red\">AI</font></strong>l\n",
    "\n",
    "Customer search:\n",
    "* I search flower for **weading.**\n",
    "* I search flower for **mother day.**\n",
    "* I search flower for **valentine day.**\n",
    "\n",
    "\n",
    "Company provide:\n",
    "* I found the same product <strong><font color=\"red\">contextualized</font></strong> to my search\n",
    "    \"\"\")\n",
    "\n",
    "    image_uri = \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"\n",
    "    images = []\n",
    "  \n",
    "    images.append(Image.open(requests.get(image_uri , stream=True).raw))\n",
    "\n",
    "    #\n",
    "    \n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            search = gr.Textbox(label=\"Search a product\", placeholder=\"Try: Flower, tree, Bouquets, Roses... \")\n",
    "            theme = gr.Textbox(label=\"Thema\", placeholder=\"Try: weading, mother day, valentine days, Anniversary, Marriage, For pleasure, Congratulation, Birth...\")\n",
    "            \n",
    "            language= gr.Textbox(label=\"Description language\", placeholder=\"Try: FR, ES, NL, EN...\")\n",
    "\n",
    "            gallery_photos = gr.Gallery(\n",
    "                label=\"Generated images\", show_label=False, elem_id=\"gallery_id\"\n",
    "                ).style(columns=[2], rows=[2], object_fit=\"contain\", height=\"auto\")\n",
    "\n",
    "            gallery_photos.select(\n",
    "                get_select_index, images_selected_state, images_selected_state).then(\n",
    "                None, images_selected_state, None, _js=js_pos_select)\n",
    "\n",
    "            with gr.Accordion(\"Destination prompt advanced settings\", open=False):\n",
    "                gr.Markdown(\"Make changes to the destination prompt default settings\")\n",
    "                temperature = gr.Slider(0, 1, 0.3, label=\"temperature\")\n",
    "                top_k = gr.Slider(0, 40, 40, label=\"top_k\")\n",
    "                top_p = gr.Slider(0, 1, 1, label=\"top_p\")\n",
    "                max_output_tokens = gr.Slider(0, 1024, 700, label=\"max_output_tokens\")\n",
    "                \n",
    "                images_selected_state = gr.JSON([], visible=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with gr.Column():\n",
    "            btn = gr.Button(\"Run\")\n",
    "            product_desc_prompt_out = gr.Textbox(label=\"Product description\")\n",
    "            product_composition_prompt_out = gr.Textbox(label=\"Product composition\")\n",
    "            \n",
    "            product_images = gr.Gallery(label=\"Generated images\", show_label=False, elem_id=\"gallery\").style(columns=[3], rows=[2], object_fit=\"contain\", height=\"auto\")\n",
    "\n",
    "\n",
    "    \n",
    "    product_photo_prompt_out = \"test\"\n",
    "            \n",
    "    inputs_array = [search,\n",
    "                    theme,\n",
    "                    language,\n",
    "                    temperature,                    \n",
    "                    top_k,\n",
    "                    top_p,\n",
    "                    max_output_tokens]\n",
    "    \n",
    "    outputs_array = [product_desc_prompt_out ,\n",
    "                     product_composition_prompt_out,\n",
    "                     product_images\n",
    "                     #, product_photo_prompt_out\n",
    "#                                ,gr.Textbox(label=\"Image Generated Prompt\")\n",
    "#                         , product_images\n",
    "                         ]\n",
    "    \n",
    "    \n",
    "    demo_genretail.load(Load_images, None, gallery_photos)\n",
    "    \n",
    "\n",
    "    btn.click(fn=update, inputs=inputs_array, outputs=outputs_array )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #, examples=[\"genAI/examples/B2BDP-GALLERY-0-1.jpg\", \"examples/B2BDP-GALLERY-0-1.jpg\", \"genAI/examples/B5CL-GALLERY-0-2.jpg\"])\n",
    "    \n",
    "    \n",
    " \n",
    "demo_genretail.launch(share=True, debug=True)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    # Set debug=True in Colab for live debugging\n",
    "    # To create a public link, set `share=True` in `launch()`.\n",
    "\n",
    "#    demo_genretail.launch(share=True, debug=True)\n",
    "#     demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ec02509-82ca-4987-8ab1-b8c8e1367d43",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "! pip3 install --upgrade pip\n",
    "! pip3 install torchvision==0.14.1\n",
    "! pip3 install transformers==4.27.1\n",
    "! pip3 install diffusers==0.15.1\n",
    "! pip3 install datasets==2.9.0\n",
    "! pip3 install accelerate==0.18.0\n",
    "! pip3 install triton==2.0.0.dev20221120\n",
    "! pip3 install xformers==0.0.16\n",
    "# Install gdown for downloading example training images.\n",
    "! pip3 install gdown\n",
    "# Remove wrong cublas version.\n",
    "! pip3 uninstall nvidia_cublas_cu11 --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8042cc76-f111-4a1e-9da7-698b46e42ae9",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6308e0d3-242e-4b5d-982c-bebc39a12957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636271c4-528c-47fb-ac9a-7a2137feffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://4d9d89fcb2e4ad26c5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4d9d89fcb2e4ad26c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0]\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7866 <> https://4d9d89fcb2e4ad26c5.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "URL = \"https://source.unsplash.com/random/500x500/?nature,fruit\"\n",
    "\n",
    "URL = \"https://medias.interflora.fr/fstrz/r/s/c/medias.interflora.fr/medias/2FRI-GALLERY-0-1.jpg?frz-width=643&context=bWFzdGVyfGltYWdlc3wyMDkwMjJ8aW1hZ2UvanBlZ3xpbWFnZXMvaGJjL2g4Ny85NTMwNjA5NTk4NDk0LmpwZ3xlM2Y0NmE0YWY3YjQ3MjcyMzRhNmEwOTE3MjY5OTMxOWU1OGQ4ZmU0MWM2ZTI3NDRkODAzNTllOWYyMzVkMTRm\"\n",
    "\n",
    "\n",
    "js_pos_select = \"\"\"\n",
    "async (images_selected_state) => {\n",
    "  const gallery = document.querySelector(\"#gallery_id\")\n",
    "  const buttons_thumbnails = gallery.querySelectorAll(\".thumbnails > button\");\n",
    "  const buttons_large = gallery.querySelectorAll(\".grid-container > button\");\n",
    "  buttons_thumbnails.forEach((btn, idx) => {\n",
    "    if(images_selected_state.includes(idx)){\n",
    "      btn.classList.add('selected-custom');\n",
    "    }else{\n",
    "      btn.classList.remove('selected-custom');\n",
    "    }\n",
    "  })\n",
    "  buttons_large.forEach((btn, idx) => {\n",
    "    if(images_selected_state.includes(idx)){\n",
    "      btn.classList.add('selected-custom');\n",
    "    }else{\n",
    "      btn.classList.remove('selected-custom');\n",
    "    }\n",
    "  })\n",
    "  return images_selected_state\n",
    "}\n",
    "\"\"\"\n",
    "css = \"\"\"\n",
    ".selected-custom {\n",
    "    --ring-color: red !important;\n",
    "    transform: scale(0.9) !important;\n",
    "    border-color: red !important;\n",
    "}\n",
    "\"\"\"\n",
    "def get_random_images(n=1):\n",
    "    images = []\n",
    "    #  for i in range(n):\n",
    "    images.append(Image.open(requests.get(URL , stream=True).raw))\n",
    "    return images\n",
    "\n",
    "def get_select_index(imgs_set, evt: gr.SelectData):\n",
    "  print(evt.index)\n",
    "  if(evt.index in imgs_set):\n",
    "    imgs_set.pop(imgs_set.index(evt.index))\n",
    "  else:\n",
    "    imgs_set.append(evt.index)\n",
    "  print(imgs_set)\n",
    "  return imgs_set\n",
    "\n",
    "with gr.Blocks(css=css) as demo:\n",
    "    images_selected_state = gr.JSON([], visible=False)\n",
    "\n",
    "    with gr.Column(variant=\"panel\"):\n",
    "        with gr.Row(variant=\"compact\"):\n",
    "            btn = gr.Button(\"Generate image\").style(full_width=False)\n",
    "\n",
    "        gallery_photos = gr.Gallery(\n",
    "            label=\"Generated images\", show_label=False, elem_id=\"gallery_id\"\n",
    "        ).style(columns=[4], rows=[2], object_fit=\"contain\", height=\"auto\")\n",
    "\n",
    "    gallery_photos.select(\n",
    "        get_select_index, images_selected_state, images_selected_state).then(\n",
    "        None, images_selected_state, None, _js=js_pos_select)\n",
    "    demo.load(get_random_images, None, gallery_photos)\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc09e25-f3f5-45f4-a2fb-a77562129080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab1a7d5-850e-45e1-b57e-36f4a9c6fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b492a54f-6554-473c-82b1-d396acc270b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from google.cloud import aiplatform, storage\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def create_job_name(prefix):\n",
    "    user = os.environ.get(\"USER\")\n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    job_name = f\"{prefix}-{user}-{now}\"\n",
    "    return job_name\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "\n",
    "def image_to_base64(image, format=\"JPEG\"):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=format)\n",
    "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return image_str\n",
    "\n",
    "\n",
    "def base64_to_image(image_str):\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows=2, cols=2):\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def deploy_model(model_id, task):\n",
    "    model_name = \"stable-diffusion-v1\"\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-{task}-endpoint\")\n",
    "    serving_env = {\n",
    "        \"MODEL_ID\": model_id,\n",
    "        \"TASK\": task,\n",
    "    }\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_name,\n",
    "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
    "        serving_container_ports=[7080],\n",
    "        serving_container_predict_route=\"/predictions/diffusers_serving\",\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        serving_container_environment_variables=serving_env,\n",
    "    )\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=\"n1-standard-8\",\n",
    "        accelerator_type=\"NVIDIA_TESLA_V100\",\n",
    "        accelerator_count=1,\n",
    "        deploy_request_timeout=1800,\n",
    "        service_account=SERVICE_ACCOUNT,\n",
    "    )\n",
    "    return model, endpoint\n",
    "\n",
    "\n",
    "def get_bucket_and_blob_name(filepath):\n",
    "    # The gcs path is of the form gs://<bucket-name>/<blob-name>\n",
    "    gs_suffix = filepath.split(\"gs://\", 1)[1]\n",
    "    return tuple(gs_suffix.split(\"/\", 1))\n",
    "\n",
    "\n",
    "def upload_local_dir_to_gcs(local_dir_path, gcs_dir_path):\n",
    "    \"\"\"Uploads files in a local directory to a GCS directory.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket_name = gcs_dir_path.split(\"/\")[2]\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    for local_file in glob.glob(local_dir_path + \"/**\"):\n",
    "        if not os.path.isfile(local_file):\n",
    "            continue\n",
    "        filename = local_file[1 + len(local_dir_path) :]\n",
    "        gcs_file_path = os.path.join(gcs_dir_path, filename)\n",
    "        _, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob.upload_from_filename(local_file)\n",
    "        print(\"Copied {} to {}.\".format(local_file, gcs_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ccec11-ecae-4059-97f4-741f13c2fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 18:56:56.829234: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-31 18:57:00.478886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-31 18:57:00.479040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-31 18:57:00.479053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>model_id = <span style=\"color: #808000; text-decoration-color: #808000\">\"runwayml/stable-diffusion-v1-5\"</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5 pipe = pipe.to(<span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>prompt = <span style=\"color: #808000; text-decoration-color: #808000\">\"a photo of an astronaut riding a horse on mars\"</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>image = pipe(prompt).images[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/diffusers/pipelines/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">643</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 641 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>is_offloaded = pipeline_is_offloaded <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> pipeline_is_sequentially_offloaded        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> modules:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 643 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module.to(torch_device, torch_dtype)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 645 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>module.dtype == torch.float16                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(torch_device) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> [<span style=\"color: #808000; text-decoration-color: #808000\">\"cpu\"</span>]                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1811</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1808 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" model has already been set to the correct devices and casted to the co</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1809 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1810 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1811 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().to(*args, **kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1812 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1813 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">half</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1814 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Checks if the model has been loaded in 8-bit</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">989</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 986 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 987 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 988 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 989 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 990 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 991 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_backward_hook</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 992 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, hook: Callable[[<span style=\"color: #808000; text-decoration-color: #808000\">'Module'</span>, _grad_t, _grad_t], Union[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, Tensor]]           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 661 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># track autograd history of `param_applied`, so we have to use</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 662 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># `with torch.no_grad():`</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 663 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param_applied = fn(param)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 665 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>should_use_set_data = compute_should_use_set_data(param, param_applied)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 666 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> should_use_set_data:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 667 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param.data = param_applied                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">987</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 984 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> convert_to_format <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> t.dim() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 985 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">els</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 986 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 987 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 988 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 989 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 990 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jupyter/.local/lib/python3.7/site-packages/torch/cuda/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">229</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_lazy_init</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># are found or any other error occurs</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'CUDA_MODULE_LOADING'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> os.environ:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>os.environ[<span style=\"color: #808000; text-decoration-color: #808000\">'CUDA_MODULE_LOADING'</span>] = <span style=\"color: #808000; text-decoration-color: #808000\">'LAZY'</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>229 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch._C._cuda_init()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Some of the queued calls may reentrantly call _lazy_init();</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">231 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># we need to just return without initializing in that case.</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">232 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># However, we must not let any *other* threads in!</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a \n",
       "driver from <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://www.nvidia.com/Download/index.aspx</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m5\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mmodel_id = \u001b[33m\"\u001b[0m\u001b[33mrunwayml/stable-diffusion-v1-5\u001b[0m\u001b[33m\"\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mpipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5 pipe = pipe.to(\u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0mprompt = \u001b[33m\"\u001b[0m\u001b[33ma photo of an astronaut riding a horse on mars\u001b[0m\u001b[33m\"\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0mimage = pipe(prompt).images[\u001b[94m0\u001b[0m]                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/diffusers/pipelines/\u001b[0m\u001b[1;33mpipeline_utils.py\u001b[0m:\u001b[94m643\u001b[0m in \u001b[92mto\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 641 \u001b[0m\u001b[2m│   │   \u001b[0mis_offloaded = pipeline_is_offloaded \u001b[95mor\u001b[0m pipeline_is_sequentially_offloaded        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m modules:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 643 \u001b[2m│   │   │   \u001b[0mmodule.to(torch_device, torch_dtype)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 645 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodule.dtype == torch.float16                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 646 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mand\u001b[0m \u001b[96mstr\u001b[0m(torch_device) \u001b[95min\u001b[0m [\u001b[33m\"\u001b[0m\u001b[33mcpu\u001b[0m\u001b[33m\"\u001b[0m]                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m1811\u001b[0m in \u001b[92mto\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1808 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m model has already been set to the correct devices and casted to the co\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1809 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1810 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1811 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().to(*args, **kwargs)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1812 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1813 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mhalf\u001b[0m(\u001b[96mself\u001b[0m, *args):                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1814 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Checks if the model has been loaded in 8-bit\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m989\u001b[0m in \u001b[92mto\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 986 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 987 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 988 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 989 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 990 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 991 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mregister_backward_hook\u001b[0m(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 992 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m, hook: Callable[[\u001b[33m'\u001b[0m\u001b[33mModule\u001b[0m\u001b[33m'\u001b[0m, _grad_t, _grad_t], Union[\u001b[94mNone\u001b[0m, Tensor]]           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in \u001b[92m_apply\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in \u001b[92m_apply\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in \u001b[92m_apply\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in \u001b[92m_apply\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m664\u001b[0m in \u001b[92m_apply\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 661 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# track autograd history of `param_applied`, so we have to use\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# `with torch.no_grad():`\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 663 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 664 \u001b[2m│   │   │   │   \u001b[0mparam_applied = fn(param)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 665 \u001b[0m\u001b[2m│   │   │   \u001b[0mshould_use_set_data = compute_should_use_set_data(param, param_applied)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 666 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m should_use_set_data:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 667 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mparam.data = param_applied                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/.local/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m987\u001b[0m in \u001b[92mconvert\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 984 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m convert_to_format \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m t.dim() \u001b[95min\u001b[0m (\u001b[94m4\u001b[0m, \u001b[94m5\u001b[0m):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 985 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94mels\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 986 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 987 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 988 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 989 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 990 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/.local/lib/python3.7/site-packages/torch/cuda/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m229\u001b[0m in \u001b[92m_lazy_init\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# are found or any other error occurs\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mCUDA_MODULE_LOADING\u001b[0m\u001b[33m'\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m os.environ:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2m│   │   │   \u001b[0mos.environ[\u001b[33m'\u001b[0m\u001b[33mCUDA_MODULE_LOADING\u001b[0m\u001b[33m'\u001b[0m] = \u001b[33m'\u001b[0m\u001b[33mLAZY\u001b[0m\u001b[33m'\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m229 \u001b[2m│   │   \u001b[0mtorch._C._cuda_init()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# we need to just return without initializing in that case.\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m232 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# However, we must not let any *other* threads in!\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mFound no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a \n",
       "driver from \u001b[4;94mhttp://www.nvidia.com/Download/index.aspx\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba19ad-c1cc-4fdf-ade4-a2f23aff4838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
