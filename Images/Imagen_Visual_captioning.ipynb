{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e88953-9426-4f44-a692-80bf96f8f977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-demo-384110\n",
      "1008225662928\n"
     ]
    }
   ],
   "source": [
    "# @title Parameters\n",
    "LOCATION = \"us-central1\" #@param {type:\"string\"}\n",
    "\n",
    "PROJECT_ID = !gcloud projects list --filter=\"$(gcloud config get-value project)\" --format=\"value(PROJECT_ID)\"\n",
    "\n",
    "if len(PROJECT_ID) > 1:\n",
    "    PROJECT_ID = PROJECT_ID[1]\n",
    "else:\n",
    "    PROJECT_ID = PROJECT_ID[0]\n",
    "print(PROJECT_ID)\n",
    "\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"$(gcloud config get-value project)\" --format=\"value(PROJECT_NUMBER)\"\n",
    "if len(PROJECT_NUMBER) > 1:\n",
    "    PROJECT_NUMBER = PROJECT_NUMBER[1]\n",
    "else:\n",
    "    PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "\n",
    "print(PROJECT_NUMBER)\n",
    "\n",
    "TOKEN_ENDPOINT_URI = 'https://www.googleapis.com/oauth2/v3/tokeninfo?access_token='\n",
    "\n",
    "IMAGEGEN_MODEL = \"imagegeneration@002\" #models available: imagegeneration@001 and imagegeneration@002\n",
    "ENDPOINT_URL = f'projects/{PROJECT_NUMBER}/locations/{LOCATION}/publishers/google/models/{IMAGEGEN_MODEL}'\n",
    "\n",
    "IMAGE_TEXT_MODEL = \"imagetext\"\n",
    "IMAGEN_ENDPOINT_URL = f'projects/{PROJECT_NUMBER}/locations/{LOCATION}/publishers/google/models/{IMAGE_TEXT_MODEL}'\n",
    "\n",
    "\n",
    "RATE_LIMIT = 10 #default quota 10 Online prediction requests per base model per minute per region per base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc7db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64c836c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access Token is generated for  admin@julienmiquel.altostrat.com\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "\"\"\"\n",
    "Get access token\n",
    "\"\"\"\n",
    "def get_accessToken():\n",
    "    global ACCESS_TOKEN\n",
    "    gcloud_token = !gcloud auth print-access-token\n",
    "    gcloud_tokeninfo = requests.get(TOKEN_ENDPOINT_URI + gcloud_token[0]).json()\n",
    "    print(\"Access Token is generated for \", gcloud_tokeninfo['email'])\n",
    "    ACCESS_TOKEN = gcloud_token[0]\n",
    "    return ACCESS_TOKEN\n",
    "\n",
    "ACCESS_TOKEN = get_accessToken()\n",
    "#print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ff1d84-bba0-48cb-90db-dd5782f1c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "encoding = base64.b64encode(open(img_path, 'rb').read())\n",
    "The following function takes an image file path and returns a base64 encoded image as string\n",
    "\"\"\"\n",
    "def encode_image(img_path):\n",
    "    with open(img_path, \"rb\") as img_file:\n",
    "        encoded_str = base64.b64encode(img_file.read())\n",
    "    return encoded_str\n",
    "\n",
    "\"\"\"\n",
    "decoding = base64.b64decode(encoding)\n",
    "The following function takes a base64 encoded image and returns a PIL image\n",
    "\"\"\"\n",
    "def decode_image(img_base64):\n",
    "    img_bytes = base64.b64decode(img_base64)\n",
    "    return Image.open(BytesIO(img_bytes))\n",
    "\n",
    "\"\"\"\n",
    "display_image = decode_image(encoding)\n",
    "The following function takes a PIL image and displays it\n",
    "\"\"\"\n",
    "def display_image(img):\n",
    "    display.display(img)\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "\"\"\"\n",
    "Read files from GCS bucket for a given path.\n",
    "\"\"\"\n",
    "def read_file_from_gcs(bucket_name, file_path):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(file_path)\n",
    "    return blob\n",
    "\n",
    "\"\"\"\n",
    "Read b64 encoded file from GCS bucket\n",
    "\"\"\"\n",
    "def read_b64_from_gcs(bucket_name, file_path):\n",
    "    blob = read_file_from_gcs(bucket_name, file_path)    \n",
    "    return base64.b64encode(blob.download_as_bytes())\n",
    "\n",
    "\"\"\"\n",
    "Read Json Config file from GCS bucket\n",
    "\"\"\"\n",
    "def read_json_from_gcs(bucket_name, file_path):\n",
    "    blob = read_file_from_gcs(bucket_name, file_path)\n",
    "    str_json = blob.download_as_string()\n",
    "    print(str_json)\n",
    "    json_config = json.loads(str_json)\n",
    "    return json_config\n",
    "\n",
    "\n",
    "# Utility functions for Embeddings API with rate limiting\n",
    "def rate_limit(max_per_minute):\n",
    "    import time\n",
    "\n",
    "    period = 60 / max_per_minute\n",
    "    print(\"Waiting\")\n",
    "    while True:\n",
    "        before = time.time()\n",
    "        yield\n",
    "        after = time.time()\n",
    "        elapsed = after - before\n",
    "        sleep_time = max(0, period - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            print(\".\", end=\"\")\n",
    "            time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7669987-2df2-4bac-8e3a-fa089dedaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setup\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "import base64\n",
    "\n",
    "# @title image Generation Model\n",
    "def generate_image(\n",
    "    prompt: str,\n",
    "    sampleImageSize: str,\n",
    "    sampleCount: int,\n",
    "    seed: int\n",
    "    ):\n",
    "    rate_limit(RATE_LIMIT) \n",
    "    headers = {\n",
    "      'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "      'Content-Type': 'application/json; charset=UTF-8'\n",
    "    }\n",
    "    data = {\"instances\": [{\"prompt\": prompt}],\n",
    "            \"parameters\": {\"sampleImageSize\": sampleImageSize,\"sampleCount\": sampleCount, \"seed\": seed}}\n",
    "\n",
    "    response = requests.post(f'https://{LOCATION}-aiplatform.googleapis.com/v1/{ENDPOINT_URL}:predict', data=json.dumps(data), headers=headers)\n",
    "    return response\n",
    "\n",
    "###\n",
    "# Visual Question Answering (VQA) to get image information\n",
    "##\n",
    "def visual_qa(\n",
    "    prompt: str,\n",
    "    sampleCount: int,\n",
    "    encoded_str: str\n",
    "    ):\n",
    "    rate_limit(RATE_LIMIT) \n",
    "    \n",
    "    headers = {\n",
    "      'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "      'Content-Type': 'application/json; charset=UTF-8'\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"instances\": [\n",
    "            {\n",
    "            \"prompt\": prompt,\n",
    "            \"image\": {\n",
    "                \"bytesBase64Encoded\": encoded_str\n",
    "            }\n",
    "            }\n",
    "        ],\n",
    "        \"parameters\": {\n",
    "            \"sampleCount\": sampleCount\n",
    "            }\n",
    "        }\n",
    "\n",
    "    response = requests.post(f'https://{LOCATION}-aiplatform.googleapis.com/v1/{IMAGEN_ENDPOINT_URL}:predict', \n",
    "        data=json.dumps(data), headers=headers)\n",
    "\n",
    "    return response\n",
    "\n",
    "###\n",
    "#Visual captioning is available in the following languages:\n",
    "# English (en)\n",
    "# French (fr)\n",
    "# German (de)\n",
    "# Italian (it)\n",
    "# Spanish (es)\n",
    "##\n",
    "def visual_captioning(\n",
    "    sampleCount: int,\n",
    "    language: str, \n",
    "    # English (en), French (fr), German (de), Italian (it), Spanish (es)\n",
    "    encoded_str: str\n",
    "    ):\n",
    "    rate_limit(RATE_LIMIT) \n",
    "\n",
    "    headers = {\n",
    "      'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "      'Content-Type': 'application/json; charset=UTF-8'\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"instances\": [\n",
    "            {\n",
    "            \"image\": {\n",
    "                \"bytesBase64Encoded\": encoded_str\n",
    "            }\n",
    "            }\n",
    "        ],\n",
    "        \"parameters\": {\n",
    "            \"sampleCount\": sampleCount,\n",
    "            \"language\": language\n",
    "            }\n",
    "        }\n",
    "\n",
    "    response = requests.post(f'https://{LOCATION}-aiplatform.googleapis.com/v1/{IMAGEN_ENDPOINT_URL}:predict', \n",
    "        data=json.dumps(data), headers=headers)\n",
    "\n",
    "    return response\n",
    "\n",
    "def display_images(\n",
    "    predictions: str,\n",
    "    sampleImageSize: str,\n",
    "    scale: float,\n",
    "    ):\n",
    "    width = int(sampleImageSize) * scale\n",
    "    height = int(sampleImageSize) * scale\n",
    "    for index, key in enumerate(predictions):\n",
    "        display.display(display.Image(base64.b64decode(predictions[index]['bytesBase64Encoded']), width = width, height = height))\n",
    "        print()\n",
    "\n",
    "def print_text_response(response):\n",
    "    if response.status_code == 200:\n",
    "        json_response = json.loads(response.text)\n",
    "        #print(json_response)\n",
    "        predictions = json_response['predictions']\n",
    "        print(predictions)\n",
    "        return predictions\n",
    "    print(response)\n",
    "    response.\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb035299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual_captioning:\n",
      "<Response [400]>\n",
      "visual_qa:\n",
      "<Response [400]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "base_image_path = \"/Users/julienmiquel/dev/github-genAI/genAI/examples/B5CL-GALLERY-0-2.jpg\"\n",
    "\n",
    "print(\"visual_captioning:\")\n",
    "print_text_response(visual_captioning( 3, \"fr\",str(encode_image(base_image_path), 'UTF-8')))\n",
    "\n",
    "print(\"visual_qa:\")\n",
    "print_text_response(visual_qa(\"What is the color of the product ?\", 3,str(encode_image(base_image_path), 'UTF-8')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Prediction for the Logo\n",
    "prompt = f\"\"\"Design of abstract logo featuring a dog in blue on a pink background. \n",
    "Include lines as an additional design element. \"\"\"\n",
    "size = 256 \n",
    "\n",
    "print(prompt)\n",
    "response = generate_image(prompt,\n",
    "                                    size, # sampleImageSize\n",
    "                                    4, # sampleCount\n",
    "                                    0  # seed\n",
    "                                    )\n",
    "print(response)\n",
    "json_response = json.loads(response.text)\n",
    "predictions = json_response['predictions']\n",
    "display_images(predictions,size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ccbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
