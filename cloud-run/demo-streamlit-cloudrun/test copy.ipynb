{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcribe_gcs\n",
      "name: \"projects/59602385614/locations/us-central1/recognizers/chirp-fr-fr-demo1\"\n",
      "uid: \"65b360e8-0000-2810-b6c4-24058880b348\"\n",
      "model: \"chirp\"\n",
      "language_codes: \"fr-FR\"\n",
      "default_recognition_config {\n",
      "  model: \"chirp\"\n",
      "  language_codes: \"fr-FR\"\n",
      "}\n",
      "state: ACTIVE\n",
      "create_time {\n",
      "  seconds: 1706201361\n",
      "  nanos: 450691000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1706201361\n",
      "  nanos: 450691000\n",
      "}\n",
      "etag: \"\\\"Rpr1AiWyM/Ja\\\"\"\n",
      "\n",
      "Created recognizer: projects/59602385614/locations/us-central1/recognizers/chirp-fr-fr-demo1\n",
      "start stt operation\n",
      "finish stt operation\n"
     ]
    }
   ],
   "source": [
    "import stt as stt\n",
    "\n",
    "result = stt.transcribe_gcs(\"gs://ml-demo-eu/datasets/sound/input/02_PART_01_CHAP_02_LE_MONASTERE.mp3\", \n",
    "                            \"gs://ml-demo-eu/datasets/stt/fr-FR/02_PART_01_CHAP_02_LE_MONASTERE.mp3\",\"fr-FR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud project set customer-demo-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results {\n",
      "  key: \"gs://customer-demo-01-eu/audio-files/audiobook/01_PART_01_CHAP_01_PARTIR.mp3\"\n",
      "  value {\n",
      "    metadata {\n",
      "      total_billed_duration {\n",
      "        seconds: 572\n",
      "      }\n",
      "    }\n",
      "    cloud_storage_result {\n",
      "      uri: \"gs://customer-demo-01-eu/transcripts/01_PART_01_CHAP_01_PARTIR_transcript_65b9925f-0000-21d6-822f-582429bd4c38.json\"\n",
      "    }\n",
      "    uri: \"gs://customer-demo-01-eu/transcripts/01_PART_01_CHAP_01_PARTIR_transcript_65b9925f-0000-21d6-822f-582429bd4c38.json\"\n",
      "  }\n",
      "}\n",
      "total_billed_duration {\n",
      "  seconds: 572\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "\n",
    "from google.cloud.speech_v2 import SpeechClient\n",
    "from google.cloud.speech_v2.types import cloud_speech\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "# Instantiates a client\n",
    "client = SpeechClient(    client_options=ClientOptions(api_endpoint=f\"{config.STT_REGION}-speech.googleapis.com\" , quota_project_id=config.PROJECT_ID))\n",
    "\n",
    "# The output path of the transcription result.\n",
    "workspace = \"gs://customer-demo-01-eu/transcripts\"\n",
    "\n",
    "# The name of the audio file to transcribe:\n",
    "gcs_uri = \"gs://customer-demo-01-eu/audio-files/audiobook/01_PART_01_CHAP_01_PARTIR.mp3\"\n",
    "\n",
    "# Recognizer resource name:\n",
    "name = \"projects/customer-demo-01/locations/eu/recognizers/_\"\n",
    "\n",
    "config = cloud_speech.RecognitionConfig(\n",
    "  auto_decoding_config={},\n",
    "  model=\"long\",\n",
    "  language_codes=[\"fr-FR\"],\n",
    "  features=cloud_speech.RecognitionFeatures(\n",
    "  enable_word_time_offsets=True,\n",
    "  enable_word_confidence=True,\n",
    "  enable_automatic_punctuation=True,\n",
    "  ),\n",
    ")\n",
    "\n",
    "output_config = cloud_speech.RecognitionOutputConfig(\n",
    "  gcs_output_config=cloud_speech.GcsOutputConfig(\n",
    "    uri=workspace),\n",
    ")\n",
    "\n",
    "files = [cloud_speech.BatchRecognizeFileMetadata(\n",
    "    uri=gcs_uri\n",
    ")]\n",
    "\n",
    "request = cloud_speech.BatchRecognizeRequest(\n",
    "    recognizer=name, config=config, files=files, recognition_output_config=output_config\n",
    ")\n",
    "operation = client.batch_recognize(request=request)\n",
    "print(operation.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numba (from openai-whisper)\n",
      "  Using cached numba-0.58.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from openai-whisper) (1.26.3)\n",
      "Collecting torch (from openai-whisper)\n",
      "  Downloading torch-2.2.0-cp310-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting tqdm (from openai-whisper)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Downloading more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba->openai-whisper)\n",
      "  Using cached llvmlite-0.41.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Collecting filelock (from torch->openai-whisper)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from torch->openai-whisper) (4.9.0)\n",
      "Collecting sympy (from torch->openai-whisper)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch->openai-whisper)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.3)\n",
      "Collecting fsspec (from torch->openai-whisper)\n",
      "  Using cached fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.4)\n",
      "Collecting mpmath>=0.19 (from sympy->torch->openai-whisper)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numba-0.58.1-cp310-cp310-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Downloading tiktoken-0.5.2-cp310-cp310-macosx_11_0_arm64.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.0-cp310-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached llvmlite-0.41.1-cp310-cp310-macosx_11_0_arm64.whl (28.8 MB)\n",
      "Downloading regex-2023.12.25-cp310-cp310-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801344 sha256=86cdc1608f2327702fa35369df2fea93b41adc13e6eec26ba1bc352a98f19acf\n",
      "  Stored in directory: /Users/julienmiquel/Library/Caches/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
      "Successfully built openai-whisper\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: mpmath, tqdm, sympy, regex, networkx, more-itertools, llvmlite, fsspec, filelock, torch, tiktoken, numba, openai-whisper\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.12.2 llvmlite-0.41.1 more-itertools-10.2.0 mpmath-1.3.0 networkx-3.2.1 numba-0.58.1 openai-whisper-20231117 regex-2023.12.25 sympy-1.12 tiktoken-0.5.2 torch-2.2.0 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julienmiquel/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:06.440]  14h55, la voiture d'Elisabeth Borne arrive à l'Elysée.\n",
      "[00:06.440 --> 00:08.880]  Les commentateurs politiques s'affolent.\n",
      "[00:08.880 --> 00:12.520]  Mais qu'a dit le président à la première ministre ?\n",
      "[00:12.520 --> 00:14.960]  Vie-t-elle ces derniers instants à Matignon ?\n",
      "[00:14.960 --> 00:18.280]  Pas de réponse pour l'instant, mais beaucoup de rumeurs.\n",
      "[00:18.280 --> 00:22.720]  Dans la liste pour la remplacer, Julien de Normandie, 43 ans,\n",
      "[00:22.720 --> 00:25.000]  fidèle parmi les fidèles du président.\n",
      "[00:25.000 --> 00:28.400]  Entre le chef de l'État et lui, une relation de longue date\n",
      "[00:28.560 --> 00:30.480]  et une confiance absolue.\n",
      "[00:30.480 --> 00:33.600]  Ce techno passé par le ministère de l'Agriculture\n",
      "[00:33.600 --> 00:36.360]  a été son ancien directeur de cabinet à Bercy\n",
      "[00:36.360 --> 00:41.000]  avant de piloter sa campagne présidentielle en 2017.\n",
      "[00:41.000 --> 00:45.800]  Face à l'option de Normandie, l'option Le Cornu, 37 ans,\n",
      "[00:45.800 --> 00:49.040]  et un profil très politique pour cet ancien LR.\n",
      "[00:49.040 --> 00:52.400]  Sauf que certains proches du président s'opposeraient à sa nomination,\n",
      "[00:52.400 --> 00:54.160]  comme François Bayrou,\n",
      "[00:54.160 --> 00:57.800]  même si le président du Modem officiellement est surtout pour un changement.\n",
      "[00:57.880 --> 01:02.600]  Je pense qu'un changement est nécessaire, je l'ai dit déjà depuis plusieurs semaines.\n",
      "[01:02.600 --> 01:09.880]  On a atteint la fin d'une séquence avec ces textes difficiles, mais qui sont passés.\n",
      "[01:09.880 --> 01:13.400]  Alors oui, je pense qu'il est légitime qu'il y ait du renouvellement.\n",
      "[01:13.400 --> 01:18.280]  L'enjeu aujourd'hui, et c'est un enjeu très lourd,\n",
      "[01:18.280 --> 01:25.000]  cet enjeu-là, c'est de reconstruire une confiance qui s'est hélas délitée\n",
      "[01:25.040 --> 01:28.320]  entre les Français et l'État.\n",
      "[01:29.120 --> 01:31.600]  Mais ces dernières heures, surprise !\n",
      "[01:31.600 --> 01:34.960]  C'est finalement le Benjamin du gouvernement qui tiendrait la corde,\n",
      "[01:34.960 --> 01:38.520]  Gabriel Attal, 34 ans, en pleine ascension.\n",
      "[01:38.520 --> 01:42.080]  L'ancien ministre des Comptes Publics promu à l'Éducation nationale\n",
      "[01:42.080 --> 01:44.280]  est devenu l'un des hommes forts du gouvernement,\n",
      "[01:44.280 --> 01:47.040]  en s'engageant notamment contre le harcèlement scolaire\n",
      "[01:47.040 --> 01:49.320]  et en interdisant le port de la baïa à l'école.\n",
      "[01:49.320 --> 01:53.080]  Oui, j'assume la décision que j'ai prise de dire que la baïa, le camis,\n",
      "[01:53.080 --> 01:55.520]  ne peuvent être portées à l'école.\n",
      "[01:55.520 --> 01:57.240]  Je suis conscient que derrière la baïa, le camis,\n",
      "[01:57.240 --> 02:00.200]  il y a des jeunes filles, des jeunes garçons, parfois leur famille,\n",
      "[02:00.200 --> 02:01.640]  à qui il faut expliquer les choses.\n",
      "[02:01.640 --> 02:03.320]  Donc pour répondre très concrètement à votre question,\n",
      "[02:03.320 --> 02:05.280]  une jeune fille qui se présenterait aujourd'hui\n",
      "[02:05.280 --> 02:08.120]  dans un établissement scolaire vêtue d'une abaïa\n",
      "[02:08.120 --> 02:10.200]  ne pourra pas rentrer en classe.\n",
      "[02:10.200 --> 02:12.520]  Un remaniement sous forme de supplice,\n",
      "[02:12.520 --> 02:15.480]  car les rumeurs bruisent déjà depuis au moins 15 jours.\n",
      "[02:15.480 --> 02:18.880]  Hier soir encore, Elisabeth Borne était reçue par le président\n",
      "[02:18.880 --> 02:21.560]  pour évoquer les dossiers en cours.\n",
      "[02:21.600 --> 02:24.440]  En sursis, certains membres du gouvernement ont tenté\n",
      "[02:24.440 --> 02:27.520]  de se rappeler aux bons souvenirs d'Emmanuel Macron.\n",
      "[02:27.520 --> 02:30.080]  C'est le cas du ministre des Transports Clément Beaune,\n",
      "[02:30.080 --> 02:33.200]  soupçonné d'avoir mené une fronde contre la loi immigration\n",
      "[02:33.200 --> 02:35.440]  et qui jeudi dernier faisait marche arrière\n",
      "[02:35.440 --> 02:38.240]  dans une interview aux Parisiens.\n",
      "[02:38.240 --> 02:40.080]  Après un combat difficile, mon tempérament,\n",
      "[02:40.080 --> 02:41.760]  c'est de remonter sur le ring.\n",
      "[02:41.760 --> 02:44.720]  J'ai envie de remonter sur le ring.\n",
      "[02:44.720 --> 02:46.440]  Une opération contrition,\n",
      "[02:46.440 --> 02:49.200]  également menée par son collègue chargé de l'industrie,\n",
      "[02:49.200 --> 02:50.600]  Roland Lescure.\n",
      "[02:50.640 --> 02:51.440]  On est à la tâche.\n",
      "[02:51.440 --> 02:55.520]  Je suis rentré au bureau hier et j'ai repris le travail.\n",
      "[02:55.520 --> 02:57.680]  Et je continue à faire un travail que j'adore,\n",
      "[02:57.680 --> 02:59.560]  qui était d'être le ministre de l'Industrie, vous l'avez dit,\n",
      "[02:59.560 --> 03:01.760]  à un moment absolument exceptionnel.\n",
      "[03:01.760 --> 03:02.760]  Et je pense que je ne suis pas le seul.\n",
      "[03:02.760 --> 03:03.960]  J'ai échangé avec mes collègues.\n",
      "[03:03.960 --> 03:06.440]  On s'est échangé les voeux comme tous les bons collègues.\n",
      "[03:06.440 --> 03:08.400]  Et je pense que tout le monde est au travail.\n",
      "[03:08.400 --> 03:11.080]  Les plus fragilisés auraient déjà fait leur carton,\n",
      "[03:11.080 --> 03:13.840]  comme Rima Abdulmalak, la ministre de la Culture,\n",
      "[03:13.840 --> 03:17.040]  sévèrement recadrée par le président dans l'Affaire 2 par Dieu,\n",
      "Error while terminating subprocess (pid=78187): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:17.080 --> 03:20.600]  ou Agnès Firmin-Le Bodo, ministre de la Santé par intérim,\n",
      "[03:20.600 --> 03:24.080]  soupçonnée d'avoir touché 20 000 euros de dons de la part d'un laboratoire\n",
      "[03:24.080 --> 03:26.440]  lorsqu'elle était pharmacienne.\n",
      "[03:26.440 --> 03:29.720]  Une chose est sûre, Emmanuel Macron laisse tourner l'horloge\n",
      "[03:29.720 --> 03:32.480]  pour redonner un nouveau souffle à son quinquennat.\n",
      "[03:32.480 --> 03:35.000]  Tout faire pour éviter la faute de casting\n",
      "[03:35.000 --> 03:37.240]  à cinq mois des élections européennes.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd /Users/julienmiquel/dev/video/video-intelligence-api-visualiser/assets/\n",
    "whisper cdanslair_Attal_se_prépare_Reportage.mp4 --model medium --language fr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "model_name = \"fr\"\n",
    "\n",
    "model = whisper.load_model(model_name )\n",
    "\n",
    "audio_path = \"/Users/julienmiquel/dev/video/video-intelligence-api-visualiser/assets/cdanslair_Attal_se_prépare_Reportage.mp4\"\n",
    "temperature = 0\n",
    "\n",
    "result = whisper.transcribe(model, audio_path, temperature=temperature)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seq_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mseq_eval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SeqEval\n\u001b[1;32m      3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m SeqEval()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seq_eval'"
     ]
    }
   ],
   "source": [
    "from seq_eval import SeqEval\n",
    "\n",
    "evaluator = SeqEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_name.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
    "    if args[\"language\"] is not None:\n",
    "        warnings.warn(\n",
    "            f\"{model_name} is an English-only model but receipted '{args['language']}'; using English instead.\"\n",
    "        )\n",
    "    args[\"language\"] = \"en\"\n",
    "\n",
    "temperature = args.pop(\"temperature\")\n",
    "if (increment := args.pop(\"temperature_increment_on_fallback\")) is not None:\n",
    "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, increment))\n",
    "else:\n",
    "    temperature = [temperature]\n",
    "\n",
    "if (threads := args.pop(\"threads\")) > 0:\n",
    "    torch.set_num_threads(threads)\n",
    "\n",
    "from . import load_model\n",
    "\n",
    "model = load_model(model_name, device=device, download_root=model_dir)\n",
    "\n",
    "writer = get_writer(output_format, output_dir)\n",
    "word_options = [\n",
    "    \"highlight_words\",\n",
    "    \"max_line_count\",\n",
    "    \"max_line_width\",\n",
    "    \"max_words_per_line\",\n",
    "]\n",
    "if not args[\"word_timestamps\"]:\n",
    "    for option in word_options:\n",
    "        if args[option]:\n",
    "            parser.error(f\"--{option} requires --word_timestamps True\")\n",
    "if args[\"max_line_count\"] and not args[\"max_line_width\"]:\n",
    "    warnings.warn(\"--max_line_count has no effect without --max_line_width\")\n",
    "if args[\"max_words_per_line\"] and args[\"max_line_width\"]:\n",
    "    warnings.warn(\"--max_words_per_line has no effect with --max_line_width\")\n",
    "writer_args = {arg: args.pop(arg) for arg in word_options}\n",
    "for audio_path in args.pop(\"audio\"):\n",
    "    try:\n",
    "        result = transcribe(model, audio_path, temperature=temperature, **args)\n",
    "        writer(result, audio_path, **writer_args)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"Skipping {audio_path} due to {type(e).__name__}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  gs://ml-demo-eu/datasets/stt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.operation.Operation at 0x1169e1a50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"id\": \"e7a5992f11d0e813d26793d77f757e5d\",\n",
      "      \"document\": {\n",
      "        \"name\": \"projects/384659222231/locations/global/collections/default_collection/dataStores/bigben-fr_1701269573835/branches/0/documents/e7a5992f11d0e813d26793d77f757e5d\",\n",
      "        \"id\": \"e7a5992f11d0e813d26793d77f757e5d\",\n",
      "        \"derivedStructData\": {\n",
      "          \"link\": \"https://www.bigben.fr/wp-content/uploads/2018/09/PS4OFARCADESTICK_IB_FR.pdf\",\n",
      "          \"displayLink\": \"www.bigben.fr\",\n",
      "          \"title\": \"Guide de l'utilisateur\",\n",
      "          \"htmlTitle\": \"Guide de l&#39;utilisateur\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"totalSize\": 13,\n",
      "  \"attributionToken\": \"Z_BmCgwIqpjorQYQuPPOvgISJDY1YzJjMGJkLTAwMDAtMjc0NS05NzI1LTNjMjg2ZDM1ZTAzNiIHR0VORVJJQyooxcvzF4-khiKcho4iooaOIo6-nRWmi-8XwvCeFdSynRW4maEio4CXIg\",\n",
      "  \"nextPageToken\": \"gNzATZ1MDZ2gjMjNTL1IzN50SN0cjMtADMwATLjJGMjJzY1YDJaIw_lnuyQYQr4HoqIwgExEgC\",\n",
      "  \"guidedSearchResult\": {},\n",
      "  \"summary\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "\"https://discoveryengine.googleapis.com/v1beta/projects/384659222231/locations/global/collections/default_collection/dataStores/bigben-fr_1701269573835/servingConfigs/default_search:search\" \\\n",
    "-d '{ \"query\": \"ps5 manette\", \"userPseudoId\": \"123456789\", \"pageSize\": \"1\", \"offset\": \"0\" }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"id\": \"e7a5992f11d0e813d26793d77f757e5d\",\n",
      "      \"document\": {\n",
      "        \"name\": \"projects/384659222231/locations/global/collections/default_collection/dataStores/bigben-fr_1701269573835/branches/0/documents/e7a5992f11d0e813d26793d77f757e5d\",\n",
      "        \"id\": \"e7a5992f11d0e813d26793d77f757e5d\",\n",
      "        \"derivedStructData\": {\n",
      "          \"link\": \"https://www.bigben.fr/wp-content/uploads/2018/09/PS4OFARCADESTICK_IB_FR.pdf\",\n",
      "          \"htmlTitle\": \"Guide de l&#39;utilisateur\",\n",
      "          \"title\": \"Guide de l'utilisateur\",\n",
      "          \"displayLink\": \"www.bigben.fr\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"0cfc09fe85f9cc71c67f9096c24b05d2\",\n",
      "      \"document\": {\n",
      "        \"name\": \"projects/384659222231/locations/global/collections/default_collection/dataStores/bigben-fr_1701269573835/branches/0/documents/0cfc09fe85f9cc71c67f9096c24b05d2\",\n",
      "        \"id\": \"0cfc09fe85f9cc71c67f9096c24b05d2\",\n",
      "        \"derivedStructData\": {\n",
      "          \"title\": \"FR DE NL EN\",\n",
      "          \"htmlTitle\": \"FR DE NL EN\",\n",
      "          \"displayLink\": \"www.bigben.fr\",\n",
      "          \"link\": \"https://www.bigben.fr/wp-content/uploads/sites/4/2022/08/PS5AUDIOADAPTOR_IB.pdf\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"totalSize\": 13,\n",
      "  \"attributionToken\": \"ZvBlCgsIu93orQYQg7zFIBIkNjVjMGUyOWYtMDAwMC0yOGU5LWJhMjMtMTRjMTRlZWE2ZWJjIgdHRU5FUklDKiiPpIYinIaOIqaL7xeiho4ijr6dFcXL8xfC8J4V1LKdFbiZoSKjgJci\",\n",
      "  \"nextPageToken\": \"jJWZ2EWZlRTMjRTMtMjMhJWL5UGOy0CMwADMtUWOyUGMjVjNkoRXpnJ5QYQr4b8uIsgEyEgC\",\n",
      "  \"guidedSearchResult\": {},\n",
      "  \"summary\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "\"https://discoveryengine.googleapis.com/v1beta/projects/384659222231/locations/global/collections/default_collection/dataStores/bigben-fr_1701269573835/servingConfigs/default_search:search\" \\\n",
    "-d '{ \"query\": \"ps5 manette\", \"userPseudoId\": \"123456789\", \"pageSize\": \"2\", \"offset\": \"0\" }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"id\": \"0cfc09fe85f9cc71c67f9096c24b05d2\",\n",
      "      \"document\": {\n",
      "        \"name\": \"projects/384659222231/locations/global/collections/default_collection/dataStores/bigben-fr_1701269573835/branches/0/documents/0cfc09fe85f9cc71c67f9096c24b05d2\",\n",
      "        \"id\": \"0cfc09fe85f9cc71c67f9096c24b05d2\",\n",
      "        \"derivedStructData\": {\n",
      "          \"title\": \"FR DE NL EN\",\n",
      "          \"displayLink\": \"www.bigben.fr\",\n",
      "          \"link\": \"https://www.bigben.fr/wp-content/uploads/sites/4/2022/08/PS5AUDIOADAPTOR_IB.pdf\",\n",
      "          \"htmlTitle\": \"FR DE NL EN\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"a4e073d4ad0e7680562a6e8fa3a3e484\",\n",
      "      \"document\": {\n",
      "        \"name\": \"projects/384659222231/locations/global/collections/default_collection/dataStores/bigben-fr_1701269573835/branches/0/documents/a4e073d4ad0e7680562a6e8fa3a3e484\",\n",
      "        \"id\": \"a4e073d4ad0e7680562a6e8fa3a3e484\",\n",
      "        \"derivedStructData\": {\n",
      "          \"link\": \"https://www.bigben.fr/nos-produits/accessoires-gaming/action-grip-pour-manettes-xbox-one\",\n",
      "          \"displayLink\": \"www.bigben.fr\",\n",
      "          \"title\": \"Pack de 2 action grip XB12 BIGBEN\",\n",
      "          \"htmlTitle\": \"Pack de 2 action grip XB12 BIGBEN\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"totalSize\": 13,\n",
      "  \"attributionToken\": \"ZvBlCgsIzt7orQYQ06vEVRIkNjViYjVlOGItMDAwMC0yYTc4LWIyMjgtM2MyODZkNGVjMDIyIgdHRU5FUklDKijFy_MXj6SGIpyGjiKiho4iwvCeFaaL7xeOvp0V1LKdFaOAlyK4maEi\",\n",
      "  \"nextPageToken\": \"gMyAzYlRDZ2gjMjNTL4IjMi1CO3EmMtADMwATLhhTZ1ImY1YDJaEwmwebyQYQr4fszIwgEzEgC\",\n",
      "  \"guidedSearchResult\": {},\n",
      "  \"summary\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "\"https://discoveryengine.googleapis.com/v1beta/projects/384659222231/locations/global/collections/default_collection/dataStores/bigben-fr_1701269573835/servingConfigs/default_search:search\" \\\n",
    "-d '{ \"query\": \"ps5 manette\", \"userPseudoId\": \"123456789\", \"pageSize\": \"2\", \"offset\": \"1\" }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
