{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://www.lequipe.fr/Rugby/Actualites/Ecosse-trois-changements-face-a-la-france-pour-le-tournoi-des-six-nations/1447566\")\n",
    "data = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:\n",
      "Écosse : trois changements face à la France pour le Tournoi des Six Nations - L'Équipe \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Preview:\")\n",
    "print(texts[0].page_content, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Écosse #France #TournoiDesSixNations #LÉquipe\n"
     ]
    }
   ],
   "source": [
    "prompt = \"generate hashtag:\" + texts[0].page_content\n",
    "\n",
    "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 0.1.4\n",
      "Vertex AI SDK version: 1.40.0\n"
     ]
    }
   ],
   "source": [
    "# Utils\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from google.cloud import aiplatform\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "# LangChain\n",
    "import langchain\n",
    "from pydantic import BaseModel\n",
    "\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "\n",
    "# Vertex AI\n",
    "\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
    "#Next you will define some utility functions that you will use for the Vertex AI Embeddings API\n",
    "\n",
    "# Utility functions for Embeddings API with rate limiting\n",
    "def rate_limit(max_per_minute):\n",
    "    period = 60 / max_per_minute\n",
    "    print(\"Waiting\")\n",
    "    while True:\n",
    "        before = time.time()\n",
    "        yield\n",
    "        after = time.time()\n",
    "        elapsed = after - before\n",
    "        sleep_time = max(0, period - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            print(\".\", end=\"\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_community.llms.vertexai import _VertexAICommon\n",
    "\n",
    "\n",
    "class CustomVertexAIEmbeddings(_VertexAICommon, Embeddings):\n",
    "    requests_per_minute: int\n",
    "    num_instances_per_batch: int\n",
    "\n",
    "    # Overriding embed_documents method\n",
    "    def embed_documents(self, texts: List[str]):\n",
    "        limiter = rate_limit(self.requests_per_minute)\n",
    "        results = []\n",
    "        docs = list(texts)\n",
    "\n",
    "        while docs:\n",
    "            # Working in batches because the API accepts maximum 5\n",
    "            # documents per request to get embeddings\n",
    "            head, docs = (\n",
    "                docs[: self.num_instances_per_batch],\n",
    "                docs[self.num_instances_per_batch :],\n",
    "            )\n",
    "            chunk = self.client.get_embeddings(head)\n",
    "            results.extend(chunk)\n",
    "            next(limiter)\n",
    "\n",
    "        return [r.values for r in results]\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "            \"\"\"Embed a text.\n",
    "\n",
    "            Args:\n",
    "                text: The text to embed.\n",
    "\n",
    "            Returns:\n",
    "                Embedding for the text.\n",
    "            \"\"\"\n",
    "            embeddings = self.embed([text], 1, \"RETRIEVAL_QUERY\")\n",
    "            return embeddings[0]    \n",
    "\n",
    "# LLM model\n",
    "llm = VertexAI(\n",
    "    model_name=\"text-bison@001\",\n",
    "    max_output_tokens=256,\n",
    "    temperature=0.1,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Embedding\n",
    "EMBEDDING_QPM = 100\n",
    "EMBEDDING_NUM_BATCH = 5\n",
    "embeddings = CustomVertexAIEmbeddings(\n",
    "     model_name=\"textembedding-gecko@002\",\n",
    "    requests_per_minute=EMBEDDING_QPM,\n",
    "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Embed your texts\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages/langchain_core/vectorstores.py:508\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    507\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/github-genAI/genAI/.venv/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:959\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    940\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m    941\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m    961\u001b[0m         texts,\n\u001b[1;32m    962\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    967\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[21], line 22\u001b[0m, in \u001b[0;36mCustomVertexAIEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m docs:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Working in batches because the API accepts maximum 5\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# documents per request to get embeddings\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     head, docs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     19\u001b[0m         docs[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_instances_per_batch],\n\u001b[1;32m     20\u001b[0m         docs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_instances_per_batch :],\n\u001b[1;32m     21\u001b[0m     )\n\u001b[0;32m---> 22\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m(head)\n\u001b[1;32m     23\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(chunk)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mnext\u001b[39m(limiter)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_embeddings'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Embed your texts\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
