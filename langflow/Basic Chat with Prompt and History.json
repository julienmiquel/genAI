{"name":"Basic Chat with Prompt and History","description":"A simple chat with a custom prompt template and conversational memory buffer","data":{"nodes":[{"width":384,"height":307,"id":"LLMChain-934VI","type":"genericNode","position":{"x":1250.1806448178158,"y":588.4657451068704},"data":{"type":"LLMChain","node":{"template":{"callbacks":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"callbacks","advanced":false,"info":"","type":"langchain.callbacks.base.BaseCallbackHandler","list":true},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","advanced":false,"info":"","type":"BaseLanguageModel","list":false},"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","advanced":false,"info":"","type":"BaseMemory","list":false},"output_parser":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_parser","advanced":false,"info":"","type":"BaseLLMOutputParser","list":false},"prompt":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"prompt","advanced":false,"info":"","type":"BasePromptTemplate","list":false},"llm_kwargs":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"llm_kwargs","advanced":false,"info":"","type":"code","list":false},"output_key":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"text","password":false,"name":"output_key","advanced":true,"info":"","type":"str","list":false},"return_final_only":{"required":false,"placeholder":"","show":false,"multiline":false,"value":true,"password":false,"name":"return_final_only","advanced":false,"info":"","type":"bool","list":false},"tags":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"tags","advanced":false,"info":"","type":"str","list":true},"verbose":{"required":false,"placeholder":"","show":true,"multiline":false,"value":false,"password":false,"name":"verbose","advanced":true,"info":"","type":"bool","list":false},"_type":"LLMChain"},"description":"Chain to run queries against LLMs.","base_classes":["Chain","LLMChain","function"],"display_name":"LLMChain","documentation":"https://python.langchain.com/docs/modules/chains/foundational/llm_chain"},"id":"LLMChain-934VI","value":null},"selected":false,"positionAbsolute":{"x":1250.1806448178158,"y":588.4657451068704},"dragging":false},{"width":384,"height":265,"id":"PromptTemplate-a7v1K","type":"genericNode","position":{"x":172.18064481781585,"y":67.26574510687044},"data":{"type":"PromptTemplate","node":{"template":{"output_parser":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_parser","advanced":false,"info":"","type":"BaseOutputParser","list":false},"input_variables":{"required":true,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_variables","advanced":false,"info":"","type":"str","list":true},"partial_variables":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"partial_variables","advanced":false,"info":"","type":"code","list":false},"template":{"required":true,"placeholder":"","show":true,"multiline":true,"password":false,"name":"template","advanced":false,"info":"","type":"prompt","list":false,"value":"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\n{history}\nHuman: {text}\nAI:"},"template_format":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"f-string","password":false,"name":"template_format","advanced":false,"info":"","type":"str","list":false},"validate_template":{"required":false,"placeholder":"","show":false,"multiline":false,"value":true,"password":false,"name":"validate_template","advanced":false,"info":"","type":"bool","list":false},"_type":"PromptTemplate"},"description":"Schema to represent a prompt for an LLM.","base_classes":["StringPromptTemplate","BasePromptTemplate","PromptTemplate"],"display_name":"PromptTemplate","documentation":"https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/"},"id":"PromptTemplate-a7v1K","value":null},"selected":false,"dragging":false,"positionAbsolute":{"x":172.18064481781585,"y":67.26574510687044}},{"width":384,"height":561,"id":"ConversationBufferMemory-wL6Ex","type":"genericNode","position":{"x":802.1806448178158,"y":43.265745106870426},"data":{"type":"ConversationBufferMemory","node":{"template":{"chat_memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"chat_memory","advanced":false,"info":"","type":"BaseChatMessageHistory","list":false},"ai_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"AI","password":false,"name":"ai_prefix","advanced":false,"info":"","type":"str","list":false},"human_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"Human","password":false,"name":"human_prefix","advanced":false,"info":"","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"input_key","advanced":false,"info":"","type":"str","list":false},"memory_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"history","password":false,"name":"memory_key","advanced":false,"info":"","type":"str","list":false},"output_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"output_key","advanced":false,"info":"","type":"str","list":false},"return_messages":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"return_messages","advanced":false,"info":"","type":"bool","list":false},"_type":"ConversationBufferMemory"},"description":"Buffer for storing conversation memory.","base_classes":["ConversationBufferMemory","BaseMemory","BaseChatMemory"],"display_name":"ConversationBufferMemory","documentation":"https://python.langchain.com/docs/modules/memory/how_to/buffer"},"id":"ConversationBufferMemory-wL6Ex","value":null},"selected":false,"positionAbsolute":{"x":802.1806448178158,"y":43.265745106870426},"dragging":false},{"width":384,"height":715,"id":"VertexAI-DV7SP","type":"genericNode","position":{"x":120.80680827166793,"y":439.1756117910696},"data":{"type":"VertexAI","node":{"template":{"callbacks":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"callbacks","advanced":false,"info":"","type":"langchain.callbacks.base.BaseCallbackHandler","list":true},"client":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"client","advanced":false,"info":"","type":"ForwardRef('_LanguageModel')","list":false},"credentials":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"credentials.json","suffixes":[".json"],"fileTypes":["json"],"password":false,"name":"credentials","advanced":false,"info":"","type":"file","list":false,"file_path":"/Users/julienmiquel/Library/Caches/langflow/196c56fd-2ff1-430e-9fa2-0dbc038e8345/c8f0cb3ff34925625dc040701cc1aec6a96d7b1d8884cba02c66211e850cc605"},"cache":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"cache","advanced":false,"info":"","type":"bool","list":false},"location":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"us-central1","password":false,"name":"location","advanced":false,"info":"","type":"str","list":false},"max_output_tokens":{"required":false,"placeholder":"","show":true,"multiline":false,"value":128,"password":false,"name":"max_output_tokens","advanced":true,"info":"","type":"int","list":false},"model_name":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"text-bison","password":false,"name":"model_name","advanced":false,"info":"","type":"str","list":false},"project":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"project","advanced":false,"info":"","type":"str","list":false},"request_parallelism":{"required":false,"placeholder":"","show":true,"multiline":false,"value":5,"password":false,"name":"request_parallelism","advanced":false,"info":"","type":"int","list":false},"stop":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"stop","advanced":false,"info":"","type":"str","list":true},"tags":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"tags","advanced":false,"info":"","type":"str","list":true},"temperature":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"0.2","password":false,"name":"temperature","advanced":false,"info":"","type":"float","list":false},"top_k":{"required":false,"placeholder":"","show":true,"multiline":false,"value":40,"password":false,"name":"top_k","advanced":true,"info":"","type":"int","list":false},"top_p":{"required":false,"placeholder":"","show":true,"multiline":false,"value":0.95,"password":false,"name":"top_p","advanced":true,"info":"","type":"float","list":false},"tuned_model_name":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"tuned_model_name","advanced":true,"info":"","type":"str","list":false},"verbose":{"required":false,"placeholder":"","show":true,"multiline":false,"value":false,"password":false,"name":"verbose","advanced":true,"info":"","type":"bool","list":false},"_type":"VertexAI"},"description":"Wrapper around Google Vertex AI large language models.","base_classes":["BaseLanguageModel","_VertexAICommon","VertexAI","LLM","BaseLLM"],"display_name":"VertexAI","documentation":"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/google_vertex_ai_palm"},"id":"VertexAI-DV7SP","value":null},"selected":true,"positionAbsolute":{"x":120.80680827166793,"y":439.1756117910696},"dragging":false}],"edges":[{"source":"PromptTemplate-a7v1K","sourceHandle":"PromptTemplate|PromptTemplate-a7v1K|StringPromptTemplate|BasePromptTemplate|PromptTemplate","target":"LLMChain-934VI","targetHandle":"BasePromptTemplate|prompt|LLMChain-934VI","className":"","id":"reactflow__edge-PromptTemplate-a7v1KPromptTemplate|PromptTemplate-a7v1K|PromptTemplate|Serializable|StringPromptTemplate|BasePromptTemplate-LLMChain-934VIBasePromptTemplate|prompt|LLMChain-934VI","style":{"stroke":"#555555"},"animated":false,"selected":false},{"source":"ConversationBufferMemory-wL6Ex","sourceHandle":"ConversationBufferMemory|ConversationBufferMemory-wL6Ex|ConversationBufferMemory|BaseMemory|BaseChatMemory","target":"LLMChain-934VI","targetHandle":"BaseMemory|memory|LLMChain-934VI","className":"","id":"reactflow__edge-ConversationBufferMemory-wL6ExConversationBufferMemory|ConversationBufferMemory-wL6Ex|ConversationBufferMemory|Serializable|BaseChatMemory|BaseMemory-LLMChain-934VIBaseMemory|memory|LLMChain-934VI","style":{"stroke":"#555555"},"animated":false,"selected":false},{"source":"VertexAI-DV7SP","sourceHandle":"VertexAI|VertexAI-DV7SP|BaseLanguageModel|_VertexAICommon|VertexAI|LLM|BaseLLM","target":"LLMChain-934VI","targetHandle":"BaseLanguageModel|llm|LLMChain-934VI","style":{"stroke":"inherit"},"className":"stroke-gray-900 dark:stroke-gray-200","animated":false,"id":"reactflow__edge-VertexAI-DV7SPVertexAI|VertexAI-DV7SP|BaseLanguageModel|_VertexAICommon|VertexAI|LLM|BaseLLM-LLMChain-934VIBaseLanguageModel|llm|LLMChain-934VI","selected":false}],"viewport":{"x":7.260370883842597,"y":-4.299005929385771,"zoom":0.5938376333462173}},"id":"196c56fd-2ff1-430e-9fa2-0dbc038e8345","style":null}