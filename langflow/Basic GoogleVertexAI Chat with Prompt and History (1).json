{"name":"Basic GoogleVertexAI Chat with Prompt and History","description":"A simple chat with a custom prompt template and conversational memory buffer","data":{"nodes":[{"width":384,"height":307,"id":"LLMChain-cNmWh","type":"genericNode","position":{"x":1250.1806448178158,"y":588.4657451068704},"data":{"type":"LLMChain","node":{"template":{"callbacks":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"callbacks","advanced":false,"info":"","type":"langchain.callbacks.base.BaseCallbackHandler","list":true},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","advanced":false,"info":"","type":"BaseLanguageModel","list":false},"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","advanced":false,"info":"","type":"BaseMemory","list":false},"output_parser":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_parser","advanced":false,"info":"","type":"BaseLLMOutputParser","list":false},"prompt":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"prompt","advanced":false,"info":"","type":"BasePromptTemplate","list":false},"llm_kwargs":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"llm_kwargs","advanced":false,"info":"","type":"code","list":false},"metadata":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"metadata","advanced":false,"info":"","type":"code","list":false},"output_key":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"text","password":false,"name":"output_key","advanced":true,"info":"","type":"str","list":false},"return_final_only":{"required":false,"placeholder":"","show":false,"multiline":false,"value":true,"password":false,"name":"return_final_only","advanced":false,"info":"","type":"bool","list":false},"tags":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"tags","advanced":false,"info":"","type":"str","list":true},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"verbose","advanced":true,"info":"","type":"bool","list":false},"_type":"LLMChain"},"description":"Chain to run queries against LLMs.","base_classes":["Chain","LLMChain","function"],"display_name":"LLMChain","documentation":"https://python.langchain.com/docs/modules/chains/foundational/llm_chain"},"id":"LLMChain-cNmWh","value":null},"selected":false,"positionAbsolute":{"x":1250.1806448178158,"y":588.4657451068704},"dragging":false},{"width":384,"height":445,"id":"PromptTemplate-0hYk2","type":"genericNode","position":{"x":172.18064481781585,"y":67.26574510687044},"data":{"type":"PromptTemplate","node":{"template":{"output_parser":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_parser","advanced":false,"info":"","type":"BaseOutputParser","list":false},"input_variables":{"required":true,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_variables","advanced":false,"info":"","type":"str","list":true,"value":["history","text"]},"partial_variables":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"partial_variables","advanced":false,"info":"","type":"code","list":false},"template":{"required":true,"placeholder":"","show":true,"multiline":true,"password":false,"name":"template","advanced":false,"info":"","type":"prompt","list":false,"value":"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\n{history}\nHuman: {text}\nAI:"},"template_format":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"f-string","password":false,"name":"template_format","advanced":false,"info":"","type":"str","list":false},"validate_template":{"required":false,"placeholder":"","show":false,"multiline":false,"value":true,"password":false,"name":"validate_template","advanced":false,"info":"","type":"bool","list":false},"_type":"PromptTemplate","history":{"required":false,"placeholder":"","show":true,"multiline":true,"value":"","password":false,"name":"history","display_name":"history","advanced":false,"input_types":["Document","BaseOutputParser"],"info":"","type":"str","list":false},"text":{"required":false,"placeholder":"","show":true,"multiline":true,"value":"","password":false,"name":"text","display_name":"text","advanced":false,"input_types":["Document","BaseOutputParser"],"info":"","type":"str","list":false}},"description":"Schema to represent a prompt for an LLM.","base_classes":["PromptTemplate","BasePromptTemplate","StringPromptTemplate"],"name":"","display_name":"PromptTemplate","documentation":"https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/","custom_fields":{"template":["history","text"]},"output_types":[],"field_formatters":{"formatters":{"openai_api_key":{}},"base_formatters":{"kwargs":{},"optional":{},"list":{},"dict":{},"union":{},"multiline":{},"show":{},"password":{},"default":{},"headers":{},"dict_code_file":{},"model_fields":{"MODEL_DICT":{"OpenAI":["text-davinci-003","text-davinci-002","text-curie-001","text-babbage-001","text-ada-001"],"ChatOpenAI":["gpt-3.5-turbo-0613","gpt-3.5-turbo","gpt-3.5-turbo-16k-0613","gpt-3.5-turbo-16k","gpt-4-0613","gpt-4-32k-0613","gpt-4","gpt-4-32k"],"Anthropic":["claude-v1","claude-v1-100k","claude-instant-v1","claude-instant-v1-100k","claude-v1.3","claude-v1.3-100k","claude-v1.2","claude-v1.0","claude-instant-v1.1","claude-instant-v1.1-100k","claude-instant-v1.0"],"ChatAnthropic":["claude-v1","claude-v1-100k","claude-instant-v1","claude-instant-v1-100k","claude-v1.3","claude-v1.3-100k","claude-v1.2","claude-v1.0","claude-instant-v1.1","claude-instant-v1.1-100k","claude-instant-v1.0"]}}}}},"id":"PromptTemplate-0hYk2","value":null},"selected":false,"dragging":false,"positionAbsolute":{"x":172.18064481781585,"y":67.26574510687044}},{"width":384,"height":561,"id":"ConversationBufferMemory-luiIq","type":"genericNode","position":{"x":802.1806448178158,"y":43.265745106870426},"data":{"type":"ConversationBufferMemory","node":{"template":{"chat_memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"chat_memory","advanced":false,"info":"","type":"BaseChatMessageHistory","list":false},"ai_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"AI","password":false,"name":"ai_prefix","advanced":false,"info":"","type":"str","list":false},"human_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"Human","password":false,"name":"human_prefix","advanced":false,"info":"","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"input_key","advanced":false,"info":"The variable to be used as Chat Input when more than one variable is available.","type":"str","list":false},"memory_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"history","password":false,"name":"memory_key","advanced":false,"info":"","type":"str","list":false},"output_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"output_key","advanced":false,"info":"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)","type":"str","list":false},"return_messages":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"return_messages","advanced":false,"info":"","type":"bool","list":false},"_type":"ConversationBufferMemory"},"description":"Buffer for storing conversation memory.","base_classes":["BaseChatMemory","BaseMemory","ConversationBufferMemory"],"display_name":"ConversationBufferMemory","documentation":"https://python.langchain.com/docs/modules/memory/how_to/buffer"},"id":"ConversationBufferMemory-luiIq","value":null},"selected":false,"positionAbsolute":{"x":802.1806448178158,"y":43.265745106870426},"dragging":false},{"width":384,"height":617,"id":"ChatVertexAI-UrV4Z","type":"genericNode","position":{"x":213.29688124148265,"y":615.6626224960019},"data":{"type":"ChatVertexAI","node":{"template":{"callbacks":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"callbacks","advanced":false,"info":"","type":"langchain.callbacks.base.BaseCallbackHandler","list":true},"client":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"client","advanced":false,"info":"","type":"ForwardRef(\"'_LanguageModel'\")","list":false},"credentials":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"credentials.json","suffixes":[".json"],"fileTypes":["json"],"password":false,"name":"credentials","advanced":false,"info":"","type":"file","list":false,"file_path":"/Users/julienmiquel/Library/Caches/langflow/84ca09db-4d1d-4d9c-a368-7fd7a2ca4475/c8f0cb3ff34925625dc040701cc1aec6a96d7b1d8884cba02c66211e850cc605"},"cache":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"cache","advanced":false,"info":"","type":"bool","list":false},"location":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"us-central1","password":false,"name":"location","advanced":false,"info":"","type":"str","list":false},"max_output_tokens":{"required":false,"placeholder":"","show":true,"multiline":false,"value":128,"password":false,"name":"max_output_tokens","advanced":true,"info":"","type":"int","list":false},"max_retries":{"required":false,"placeholder":"","show":false,"multiline":false,"value":6,"password":false,"name":"max_retries","advanced":false,"info":"","type":"int","list":false},"metadata":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"metadata","advanced":false,"info":"","type":"code","list":false},"model_name":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"chat-bison","password":false,"name":"model_name","advanced":false,"info":"","type":"str","list":false},"project":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"project","advanced":false,"info":"","type":"str","list":false,"value":"ml-demo-384110"},"request_parallelism":{"required":false,"placeholder":"","show":false,"multiline":false,"value":5,"password":false,"name":"request_parallelism","advanced":false,"info":"","type":"int","list":false},"stop":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"stop","advanced":false,"info":"","type":"str","list":true},"tags":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"tags","advanced":false,"info":"","type":"str","list":true},"temperature":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"0.2","password":false,"name":"temperature","advanced":false,"info":"","type":"float","list":false},"top_k":{"required":false,"placeholder":"","show":true,"multiline":false,"value":40,"password":false,"name":"top_k","advanced":true,"info":"","type":"int","list":false},"top_p":{"required":false,"placeholder":"","show":true,"multiline":false,"value":0.95,"password":false,"name":"top_p","advanced":true,"info":"","type":"float","list":false},"verbose":{"required":false,"placeholder":"","show":true,"multiline":false,"value":false,"password":false,"name":"verbose","advanced":true,"info":"","type":"bool","list":false},"_type":"ChatVertexAI"},"description":"Wrapper around Vertex AI large language models.","base_classes":["BaseChatModel","_VertexAICommon","ChatVertexAI","BaseLanguageModel","BaseLLM"],"display_name":"ChatVertexAI","custom_fields":{},"output_types":[],"documentation":"https://python.langchain.com/docs/modules/model_io/models/chat/integrations/google_vertex_ai_palm"},"id":"ChatVertexAI-UrV4Z","value":null},"selected":false,"positionAbsolute":{"x":213.29688124148265,"y":615.6626224960019},"dragging":false}],"edges":[{"source":"PromptTemplate-0hYk2","sourceHandle":"PromptTemplate|PromptTemplate-0hYk2|PromptTemplate|BasePromptTemplate|StringPromptTemplate","target":"LLMChain-cNmWh","targetHandle":"BasePromptTemplate|prompt|LLMChain-cNmWh","className":"","id":"reactflow__edge-PromptTemplate-0hYk2PromptTemplate|PromptTemplate-0hYk2|StringPromptTemplate|Serializable|BasePromptTemplate|PromptTemplate-LLMChain-cNmWhBasePromptTemplate|prompt|LLMChain-cNmWh","style":{"stroke":"#555"},"animated":false,"selected":false},{"source":"ConversationBufferMemory-luiIq","sourceHandle":"ConversationBufferMemory|ConversationBufferMemory-luiIq|BaseChatMemory|BaseMemory|ConversationBufferMemory","target":"LLMChain-cNmWh","targetHandle":"BaseMemory|memory|LLMChain-cNmWh","className":"","id":"reactflow__edge-ConversationBufferMemory-luiIqConversationBufferMemory|ConversationBufferMemory-luiIq|ConversationBufferMemory|Serializable|BaseMemory|BaseChatMemory-LLMChain-cNmWhBaseMemory|memory|LLMChain-cNmWh","style":{"stroke":"#555"},"animated":false,"selected":false},{"source":"ChatVertexAI-UrV4Z","sourceHandle":"ChatVertexAI|ChatVertexAI-UrV4Z|BaseChatModel|_VertexAICommon|ChatVertexAI|BaseLanguageModel|BaseLLM","target":"LLMChain-cNmWh","targetHandle":"BaseLanguageModel|llm|LLMChain-cNmWh","style":{"stroke":"#555"},"className":"stroke-foreground  stroke-connection","animated":false,"id":"reactflow__edge-ChatVertexAI-UrV4ZChatVertexAI|ChatVertexAI-UrV4Z|BaseChatModel|_VertexAICommon|ChatVertexAI|BaseLanguageModel|BaseLLM-LLMChain-cNmWhBaseLanguageModel|llm|LLMChain-cNmWh","selected":false}],"viewport":{"x":-51.014653955628205,"y":12.657743715771176,"zoom":0.7811445672620014}},"id":"84ca09db-4d1d-4d9c-a368-7fd7a2ca4475","style":null}